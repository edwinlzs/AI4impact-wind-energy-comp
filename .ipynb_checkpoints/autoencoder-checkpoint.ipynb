{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Flatten,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''tansformations with OOP'''\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    '''Class containing methods to transform the imported data'''\n",
    "\n",
    "    # in OOP do u not need to call return?\n",
    "    def transform(self):\n",
    "        '''overall transformation of data'''\n",
    "        self.interpolate()\n",
    "        self.add_cyclical_features()\n",
    "        self.add_time_features()\n",
    "        self.ohe()\n",
    "        self.add_historical_windpower()\n",
    "        self.add_momentum_force()\n",
    "        self.scale()\n",
    "        return self.df\n",
    "\n",
    "    def interpolate(self):\n",
    "        '''interpolation of data'''\n",
    "        df = self.df\n",
    "        df['Time'] = df['Time'].apply(lambda x : datetime.datetime.strptime(x[:-3], '%Y/%m/%d %H:%M'))\n",
    "        df['Time'] = pd.to_datetime(df['Time'])    #why double the time conversion?\n",
    "        df.set_index('Time',inplace=True)  \n",
    "        df = df.resample('1H').asfreq()    #unsure about resample and asfreq\n",
    "        df.interpolate(method='cubic',axis=0,limit_direction='both',inplace=True)\n",
    "        self.df = df\n",
    "\n",
    "    def add_cyclical_features(self):\n",
    "        '''converts direction into cylical inputs'''\n",
    "        df = self.df\n",
    "        cols = df.columns \n",
    "        for c in cols:\n",
    "            if 'Direction' in c:\n",
    "                df[c+'_norm'] = df[c]/360\n",
    "                df[c+'_sin'] = df[c+'_norm'].apply(lambda x: np.sin(x))\n",
    "                df[c+'_cos'] = df[c+'_norm'].apply(lambda x: np.cos(x))\n",
    "                df.drop([c,c+'_norm'],inplace=True,axis=1)\n",
    "\n",
    "        self.df = df \n",
    "\n",
    "    def scale(self):\n",
    "        '''normalize entire dataframe'''\n",
    "        df = self.df\n",
    "        df = pd.DataFrame(StandardScaler().fit_transform(df),index=df.index,columns=df.columns)\n",
    "        self.df = df\n",
    "\n",
    "    def add_time_features(self):\n",
    "        '''create time inputs as attributes?'''\n",
    "        df = self.df\n",
    "        df.reset_index(inplace=True,drop=False)\n",
    "        #this is assigment of attribute?\n",
    "        df['hour'] = df['Time'].apply(lambda x: x.hour).astype(str)\n",
    "        df['month'] = df['Time'].apply(lambda x: x.month).astype(str)\n",
    "        # df['day'] = df['Time'].apply(lambda x: x.day).astype(str)\n",
    "        df.set_index('Time',inplace=True)\n",
    "        self.df = df\n",
    "\n",
    "    def ohe(self):\n",
    "        '''One hot encoding of time data'''\n",
    "        #what is this? I assume it standings for one hot encoding\n",
    "        #doesn't it affect the entire frame vs just the select month or year?\n",
    "        df = self.df\n",
    "        df = pd.get_dummies(df)\n",
    "        self.df = df\n",
    "\n",
    "    def add_historical_windpower(self):\n",
    "        '''conversion of windspeed into windpower'''\n",
    "        df = self.df\n",
    "        t = pd.read_csv('target.csv')\n",
    "        t['Time'] = pd.to_datetime(t['Time'])\n",
    "        t.set_index('Time',inplace=True)\n",
    "        #how does this standardscaler object behave?\n",
    "        target_scaler = StandardScaler().fit(t)\n",
    "        t = pd.DataFrame(target_scaler.transform(t),index=t.index,columns=t.columns)\n",
    "        df = df.join(t,how='left')\n",
    "        self.target_scaler = target_scaler\n",
    "        self.df = df\n",
    "\n",
    "    def add_momentum_force(self):\n",
    "        '''add momentum'''\n",
    "        time_lag = 18\n",
    "        df = self.df \n",
    "        df['Wind Energy Lag {}'.format(time_lag)] = df['Wind Energy'].shift(time_lag)\n",
    "        df['Wind Energy Lag {}'.format(2*time_lag)] = df['Wind Energy'].shift(2*time_lag)\n",
    "        df.dropna(axis=0,inplace=True) ####DROPPING 10 ROWS OF DATA HERE\n",
    "        # are you not subtracting the future values from present here?\n",
    "        df['Momentum'] = df['Wind Energy'] - df['Wind Energy Lag {}'.format(time_lag)]\n",
    "        df['Force'] = df['Wind Energy'] - 2*df['Wind Energy Lag {}'.format(time_lag)] + df['Wind Energy Lag {}'.format(2*time_lag)]\n",
    "        df.drop(['Wind Energy Lag {}'.format(time_lag),'Wind Energy Lag {}'.format(2*time_lag)],axis=1,inplace=True)\n",
    "        self.df = df\n",
    "\n",
    "        ### generate lagged input\n",
    "        lagged = pd.DataFrame(df['Wind Energy'].shift(1))\n",
    "        lagged.fillna(method='bfill',inplace=True)\n",
    "        lagged = StandardScaler().fit_transform(lagged.values)\n",
    "        self.lagged_input = lagged\n",
    "        \n",
    "\n",
    "    #----GETTER Functions---\n",
    "    #what are they for?\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_lagged_input(self):\n",
    "        return self.lagged_input\n",
    "\n",
    "    def get_target_scaler(self):\n",
    "        return self.target_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_b_suffix(og_name):\n",
    "    return_list = []\n",
    "    for f in og_name:\n",
    "        return_list.append(f+\"-b\")\n",
    "    return return_list\n",
    "\n",
    "locations = ['guitrancourt', 'lieusaint', \n",
    "             'lvs-pussay','parc-du-gatinais', \n",
    "             'arville','boissy-la-riviere',\n",
    "             'angerville-1','angerville-2']\n",
    "\n",
    "wind_energy = 'energy-ile-de-france'\n",
    "forecast_endpt = 'https://ai4impact.org/P003/'\n",
    "analysis_endpt = 'https://ai4impact.org/P003/historical/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = locations\n",
    "model_2 = add_b_suffix(model_1)\n",
    "models = [model_1, model_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 0\n",
    "for m in models:\n",
    "    model_num += 1\n",
    "    df = pd.read_csv(analysis_endpt+m[0]+'.csv',skiprows=3)\n",
    "    df.columns = ['Time','Speed_'+m[0],'Direction_'+m[0]]\n",
    "    df.set_index('Time',inplace=True)\n",
    "    for i in range(1,len(m)):\n",
    "        loc = m[i]\n",
    "        temp = pd.read_csv(analysis_endpt+loc+'.csv',skiprows=3)\n",
    "        temp.columns = ['Time','Speed_'+loc,'Direction_'+loc]\n",
    "        temp.set_index('Time',inplace=True)\n",
    "        df = df.merge(temp,how='left',on='Time')\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "    df.reset_index(inplace=True,drop=False)\n",
    "    df.to_csv(f'model_{model_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('model_1.csv')\n",
    "df2 = pd.read_csv('model_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('https://ai4impact.org/P003/historical/energy-ile-de-france.csv',header=None)\n",
    "target.columns = ['Time','Wind Energy']\n",
    "target.to_csv('target.csv',index=False)\n",
    "target['Time'] = pd.to_datetime(target['Time'])\n",
    "target.set_index('Time',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speed_guitrancourt</th>\n",
       "      <th>Speed_lieusaint</th>\n",
       "      <th>Speed_lvs-pussay</th>\n",
       "      <th>Speed_parc-du-gatinais</th>\n",
       "      <th>Speed_arville</th>\n",
       "      <th>Speed_boissy-la-riviere</th>\n",
       "      <th>Speed_angerville-1</th>\n",
       "      <th>Speed_angerville-2</th>\n",
       "      <th>Direction_guitrancourt_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>Wind Energy</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Force</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-08-17 20:00:00</td>\n",
       "      <td>1.731006</td>\n",
       "      <td>-0.771092</td>\n",
       "      <td>-0.848547</td>\n",
       "      <td>-1.168429</td>\n",
       "      <td>-0.792996</td>\n",
       "      <td>-0.825442</td>\n",
       "      <td>-1.100277</td>\n",
       "      <td>-1.157459</td>\n",
       "      <td>-1.157221</td>\n",
       "      <td>0.884412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.302649</td>\n",
       "      <td>-0.677287</td>\n",
       "      <td>-1.013626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-17 21:00:00</td>\n",
       "      <td>1.731115</td>\n",
       "      <td>-0.956090</td>\n",
       "      <td>-1.058139</td>\n",
       "      <td>-1.322526</td>\n",
       "      <td>-0.957032</td>\n",
       "      <td>-0.992304</td>\n",
       "      <td>-1.263382</td>\n",
       "      <td>-1.314476</td>\n",
       "      <td>-1.314195</td>\n",
       "      <td>0.861563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.433817</td>\n",
       "      <td>-0.691094</td>\n",
       "      <td>-0.946613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-17 22:00:00</td>\n",
       "      <td>1.731225</td>\n",
       "      <td>-1.112943</td>\n",
       "      <td>-1.194949</td>\n",
       "      <td>-1.371792</td>\n",
       "      <td>-1.035802</td>\n",
       "      <td>-1.070685</td>\n",
       "      <td>-1.320897</td>\n",
       "      <td>-1.366155</td>\n",
       "      <td>-1.365860</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.591219</td>\n",
       "      <td>-0.718709</td>\n",
       "      <td>-0.787457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-17 23:00:00</td>\n",
       "      <td>1.731334</td>\n",
       "      <td>-1.230406</td>\n",
       "      <td>-1.239387</td>\n",
       "      <td>-1.292701</td>\n",
       "      <td>-1.009725</td>\n",
       "      <td>-1.040206</td>\n",
       "      <td>-1.248675</td>\n",
       "      <td>-1.288803</td>\n",
       "      <td>-1.288529</td>\n",
       "      <td>0.700898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.564985</td>\n",
       "      <td>-0.276874</td>\n",
       "      <td>-0.284858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-18 00:00:00</td>\n",
       "      <td>1.731443</td>\n",
       "      <td>-1.297234</td>\n",
       "      <td>-1.171861</td>\n",
       "      <td>-1.061727</td>\n",
       "      <td>-0.859221</td>\n",
       "      <td>-0.880484</td>\n",
       "      <td>-1.022571</td>\n",
       "      <td>-1.058726</td>\n",
       "      <td>-1.058514</td>\n",
       "      <td>0.545987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.237064</td>\n",
       "      <td>0.247805</td>\n",
       "      <td>0.217741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0  Speed_guitrancourt  Speed_lieusaint  \\\n",
       "Time                                                                   \n",
       "2020-08-17 20:00:00    1.731006           -0.771092        -0.848547   \n",
       "2020-08-17 21:00:00    1.731115           -0.956090        -1.058139   \n",
       "2020-08-17 22:00:00    1.731225           -1.112943        -1.194949   \n",
       "2020-08-17 23:00:00    1.731334           -1.230406        -1.239387   \n",
       "2020-08-18 00:00:00    1.731443           -1.297234        -1.171861   \n",
       "\n",
       "                     Speed_lvs-pussay  Speed_parc-du-gatinais  Speed_arville  \\\n",
       "Time                                                                           \n",
       "2020-08-17 20:00:00         -1.168429               -0.792996      -0.825442   \n",
       "2020-08-17 21:00:00         -1.322526               -0.957032      -0.992304   \n",
       "2020-08-17 22:00:00         -1.371792               -1.035802      -1.070685   \n",
       "2020-08-17 23:00:00         -1.292701               -1.009725      -1.040206   \n",
       "2020-08-18 00:00:00         -1.061727               -0.859221      -0.880484   \n",
       "\n",
       "                     Speed_boissy-la-riviere  Speed_angerville-1  \\\n",
       "Time                                                               \n",
       "2020-08-17 20:00:00                -1.100277           -1.157459   \n",
       "2020-08-17 21:00:00                -1.263382           -1.314476   \n",
       "2020-08-17 22:00:00                -1.320897           -1.366155   \n",
       "2020-08-17 23:00:00                -1.248675           -1.288803   \n",
       "2020-08-18 00:00:00                -1.022571           -1.058726   \n",
       "\n",
       "                     Speed_angerville-2  Direction_guitrancourt_sin  ...  \\\n",
       "Time                                                                 ...   \n",
       "2020-08-17 20:00:00           -1.157221                    0.884412  ...   \n",
       "2020-08-17 21:00:00           -1.314195                    0.861563  ...   \n",
       "2020-08-17 22:00:00           -1.365860                    0.802920  ...   \n",
       "2020-08-17 23:00:00           -1.288529                    0.700898  ...   \n",
       "2020-08-18 00:00:00           -1.058514                    0.545987  ...   \n",
       "\n",
       "                      month_3   month_4   month_5   month_6   month_7  \\\n",
       "Time                                                                    \n",
       "2020-08-17 20:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-17 21:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-17 22:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-17 23:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-18 00:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "\n",
       "                      month_8   month_9  Wind Energy  Momentum     Force  \n",
       "Time                                                                      \n",
       "2020-08-17 20:00:00  3.320789 -0.270112    -0.302649 -0.677287 -1.013626  \n",
       "2020-08-17 21:00:00  3.320789 -0.270112    -0.433817 -0.691094 -0.946613  \n",
       "2020-08-17 22:00:00  3.320789 -0.270112    -0.591219 -0.718709 -0.787457  \n",
       "2020-08-17 23:00:00  3.320789 -0.270112    -0.564985 -0.276874 -0.284858  \n",
       "2020-08-18 00:00:00  3.320789 -0.270112    -0.237064  0.247805  0.217741  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.copy()\n",
    "transformer = DataTransformer(df)\n",
    "transformer.transform()\n",
    "df = transformer.get_df()\n",
    "lagged = transformer.get_lagged_input()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31765, 64), (31765,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:,df.columns!='Wind Energy'].values\n",
    "y = df['Wind Energy'].values\n",
    "X = np.concatenate((X,lagged),axis=1)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19059, 62), (12706, 62), (19059,), (12706,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.4)\n",
    "x_train_features = x_train[:,:62]\n",
    "x_test_features = x_test[:,:62]\n",
    "x_train_lagged = x_train[:,62]\n",
    "x_test_lagged = x_test[:,62]\n",
    "x_train_features.shape,x_test_features.shape,x_train_lagged.shape,x_test_lagged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "features = Input(shape = (62,), name = 'Features')\n",
    "def create_encoder(features, latent_dim = latent_dim):\n",
    "    features = Input(shape = (62,), name = 'Features')\n",
    "    X = Dense(62, activation = 'relu')(features)\n",
    "    X = Dense(32, activation = 'relu')(X)\n",
    "    LATENT = Dense(latent_dim, activation = 'relu')(X)\n",
    "    encoder = Model(features, LATENT, name = 'encoder')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(latent_dim = latent_dim):\n",
    "    LATENT_INPUTS = Input(shape = (latent_dim,))\n",
    "    X = Dense(32, activation = 'relu')(LATENT_INPUTS)\n",
    "    OUTPUTS = Dense(62, activation = 'linear')(X)\n",
    "    decoder = Model(LATENT_INPUTS, OUTPUTS, name = 'decoder')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference Model\n",
    "def energy(latent_dim = latent_dim):\n",
    "    LATENT_INPUTS = Input(shape = (latent_dim,))\n",
    "    X = Dense(64,activation='relu')(LATENT_INPUTS)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(32,activation='relu')(X)\n",
    "    X = Dense(6,activation='relu')(X)\n",
    "\n",
    "    output = Dense(1,activation='linear')(X)\n",
    "    model = Model(inputs= LATENT_INPUTS ,outputs=output, name = 'energy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Features_1:0' shape=(None, 62) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(62)\n",
    "decoder = create_decoder()\n",
    "energy = energy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(features, \n",
    "                    decoder(encoder(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Features (InputLayer)        [(None, 62)]              0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                6450      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 62)                2590      \n",
      "=================================================================\n",
      "Total params: 9,040\n",
      "Trainable params: 9,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model(features):\n",
    "    full_model = Model(inputs = features, outputs = [decoder(encoder(features)), energy(encoder(features))],\n",
    "                       name = 'complete')\n",
    "    full_model.compile(loss = {'energy': 'mse',\n",
    "                              'decoder': 'mse'},\n",
    "                      optimizer = 'adam')\n",
    "    return full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = full_model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"complete\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features (InputLayer)           [(None, 62)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, 16)           6450        Features[0][0]                   \n",
      "                                                                 Features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 62)           2590        encoder[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "energy (Model)                  (None, 1)            3373        encoder[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,413\n",
      "Trainable params: 12,413\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-11adae0dc0f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'energy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'decoder'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_test_features\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                  verbose = 1)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "hist = full_model.fit(x_train_features,\n",
    "                 {'energy': y_train, 'decoder': x_train_features},\n",
    "                 epochs=500,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 validation_data=(x_test_features, {'energy': y_test, 'decoder': x_test_features}),\n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Features (InputLayer)        [(None, 62)]              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 62)                3906      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                2016      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 6,450\n",
      "Trainable params: 6,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 62)                2046      \n",
      "=================================================================\n",
      "Total params: 2,590\n",
      "Trainable params: 2,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-a9b8d43e16e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-135-f690878a8d14>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(latent_dim)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mLATENT_INPUTS\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'energy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     model.compile(loss={'energy': 'mse',\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       raise ValueError(\n\u001b[1;32m--> 800\u001b[1;33m           'The first argument to `Layer.call` must always be passed.')\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[0mcall_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": [
    "create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "def model():\n",
    "    #encoder\n",
    "    features = Input(shape=(62,),name='Features')\n",
    "    X = Dense(62, activation = 'relu')(features)\n",
    "    X1 = Dense(32, activation = 'relu')(X)\n",
    "    encoded = Dense(latent_dim, activation = 'relu', name = 'encoder')(X1)\n",
    "    \n",
    "    #difference model\n",
    "    X2 = Dense(32,activation='relu')(encoded)\n",
    "    X3 = Dropout(0.2)(X2)\n",
    "    X4 = Dense(6,activation='relu')(X3)\n",
    "    output = Dense(1, activation='linear', name = 'energy')(X4)\n",
    "    \n",
    "    #decoder \n",
    "    X5 = Dense(32, activation = 'relu')(encoded)\n",
    "    decoded = Dense(62, activation = 'linear', name = 'autoencoder')(X5)\n",
    "    \n",
    "    model = Model(inputs = features, outputs = [output, decoded])\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features (InputLayer)           [(None, 62)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 62)           3906        Features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2016        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Dense)                 (None, 16)           528         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           544         encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            198         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           544         encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "energy (Dense)                  (None, 1)            7           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "autoencoder (Dense)             (None, 62)           2046        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,789\n",
      "Trainable params: 9,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'energy': 'mse', \n",
    "                    'autoencoder': 'mse'},\n",
    "              optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:533 train_step  **\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:183 __call__\n        y_true = self._conform_to_outputs(y_pred, y_true)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:63 _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:587 map_to_output_names\n        struct.keys(), output_names))\n\n    ValueError: Found unexpected keys that do not correspond to any Model output: dict_keys(['autoencoder']). Expected: ['decoder', 'energy']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-327723447c11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'energy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'autoencoder'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_test_features\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                  verbose = 1)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 506\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:533 train_step  **\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:183 __call__\n        y_true = self._conform_to_outputs(y_pred, y_true)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:63 _conform_to_outputs\n        struct = map_to_output_names(outputs, self._output_names, struct)\n    C:\\Users\\keith\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:587 map_to_output_names\n        struct.keys(), output_names))\n\n    ValueError: Found unexpected keys that do not correspond to any Model output: dict_keys(['autoencoder']). Expected: ['decoder', 'energy']\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_features,\n",
    "                 {'energy': y_train, 'autoencoder': x_train_features},\n",
    "                 epochs=500,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 validation_data=(x_test_features, {'energy': y_test, 'autoencoder': x_test_features}),\n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.framework.test_util.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
