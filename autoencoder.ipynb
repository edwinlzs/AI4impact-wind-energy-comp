{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Flatten,Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''tansformations with OOP'''\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    '''Class containing methods to transform the imported data'''\n",
    "\n",
    "    # in OOP do u not need to call return?\n",
    "    def transform(self):\n",
    "        '''overall transformation of data'''\n",
    "        self.interpolate()\n",
    "        self.add_cyclical_features()\n",
    "        self.add_time_features()\n",
    "        self.ohe()\n",
    "        self.add_historical_windpower()\n",
    "        self.add_momentum_force()\n",
    "        self.scale()\n",
    "        return self.df\n",
    "\n",
    "    def interpolate(self):\n",
    "        '''interpolation of data'''\n",
    "        df = self.df\n",
    "        df['Time'] = df['Time'].apply(lambda x : datetime.datetime.strptime(x[:-3], '%Y/%m/%d %H:%M'))\n",
    "        df['Time'] = pd.to_datetime(df['Time'])    #why double the time conversion?\n",
    "        df.set_index('Time',inplace=True)  \n",
    "        df = df.resample('1H').asfreq()    #unsure about resample and asfreq\n",
    "        df.interpolate(method='cubic',axis=0,limit_direction='both',inplace=True)\n",
    "        self.df = df\n",
    "\n",
    "    def add_cyclical_features(self):\n",
    "        '''converts direction into cylical inputs'''\n",
    "        df = self.df\n",
    "        cols = df.columns \n",
    "        for c in cols:\n",
    "            if 'Direction' in c:\n",
    "                df[c+'_norm'] = df[c]/360\n",
    "                df[c+'_sin'] = df[c+'_norm'].apply(lambda x: np.sin(x))\n",
    "                df[c+'_cos'] = df[c+'_norm'].apply(lambda x: np.cos(x))\n",
    "                df.drop([c,c+'_norm'],inplace=True,axis=1)\n",
    "\n",
    "        self.df = df \n",
    "\n",
    "    def scale(self):\n",
    "        '''normalize entire dataframe'''\n",
    "        df = self.df\n",
    "        df = pd.DataFrame(StandardScaler().fit_transform(df),index=df.index,columns=df.columns)\n",
    "        self.df = df\n",
    "\n",
    "    def add_time_features(self):\n",
    "        '''create time inputs as attributes?'''\n",
    "        df = self.df\n",
    "        df.reset_index(inplace=True,drop=False)\n",
    "        #this is assigment of attribute?\n",
    "        df['hour'] = df['Time'].apply(lambda x: x.hour).astype(str)\n",
    "        df['month'] = df['Time'].apply(lambda x: x.month).astype(str)\n",
    "        # df['day'] = df['Time'].apply(lambda x: x.day).astype(str)\n",
    "        df.set_index('Time',inplace=True)\n",
    "        self.df = df\n",
    "\n",
    "    def ohe(self):\n",
    "        '''One hot encoding of time data'''\n",
    "        #what is this? I assume it standings for one hot encoding\n",
    "        #doesn't it affect the entire frame vs just the select month or year?\n",
    "        df = self.df\n",
    "        df = pd.get_dummies(df)\n",
    "        self.df = df\n",
    "\n",
    "    def add_historical_windpower(self):\n",
    "        '''conversion of windspeed into windpower'''\n",
    "        df = self.df\n",
    "        t = pd.read_csv('target.csv')\n",
    "        t['Time'] = pd.to_datetime(t['Time'])\n",
    "        t.set_index('Time',inplace=True)\n",
    "        #how does this standardscaler object behave?\n",
    "        target_scaler = StandardScaler().fit(t)\n",
    "        t = pd.DataFrame(target_scaler.transform(t),index=t.index,columns=t.columns)\n",
    "        df = df.join(t,how='left')\n",
    "        self.target_scaler = target_scaler\n",
    "        self.df = df\n",
    "\n",
    "    def add_momentum_force(self):\n",
    "        '''add momentum'''\n",
    "        time_lag = 18\n",
    "        df = self.df \n",
    "        df['Wind Energy Lag {}'.format(time_lag)] = df['Wind Energy'].shift(time_lag)\n",
    "        df['Wind Energy Lag {}'.format(2*time_lag)] = df['Wind Energy'].shift(2*time_lag)\n",
    "        df.dropna(axis=0,inplace=True) ####DROPPING 10 ROWS OF DATA HERE\n",
    "        # are you not subtracting the future values from present here?\n",
    "        df['Momentum'] = df['Wind Energy'] - df['Wind Energy Lag {}'.format(time_lag)]\n",
    "        df['Force'] = df['Wind Energy'] - 2*df['Wind Energy Lag {}'.format(time_lag)] + df['Wind Energy Lag {}'.format(2*time_lag)]\n",
    "        df.drop(['Wind Energy Lag {}'.format(time_lag),'Wind Energy Lag {}'.format(2*time_lag)],axis=1,inplace=True)\n",
    "        self.df = df\n",
    "\n",
    "        ### generate lagged input\n",
    "        lagged = pd.DataFrame(df['Wind Energy'].shift(1))\n",
    "        lagged.fillna(method='bfill',inplace=True)\n",
    "        lagged = StandardScaler().fit_transform(lagged.values)\n",
    "        self.lagged_input = lagged\n",
    "        \n",
    "\n",
    "    #----GETTER Functions---\n",
    "    #what are they for?\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    def get_lagged_input(self):\n",
    "        return self.lagged_input\n",
    "\n",
    "    def get_target_scaler(self):\n",
    "        return self.target_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_b_suffix(og_name):\n",
    "    return_list = []\n",
    "    for f in og_name:\n",
    "        return_list.append(f+\"-b\")\n",
    "    return return_list\n",
    "\n",
    "locations = ['guitrancourt', 'lieusaint', \n",
    "             'lvs-pussay','parc-du-gatinais', \n",
    "             'arville','boissy-la-riviere',\n",
    "             'angerville-1','angerville-2']\n",
    "\n",
    "wind_energy = 'energy-ile-de-france'\n",
    "forecast_endpt = 'https://ai4impact.org/P003/'\n",
    "analysis_endpt = 'https://ai4impact.org/P003/historical/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = locations\n",
    "model_2 = add_b_suffix(model_1)\n",
    "models = [model_1, model_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 0\n",
    "for m in models:\n",
    "    model_num += 1\n",
    "    df = pd.read_csv(analysis_endpt+m[0]+'.csv',skiprows=3)\n",
    "    df.columns = ['Time','Speed_'+m[0],'Direction_'+m[0]]\n",
    "    df.set_index('Time',inplace=True)\n",
    "    for i in range(1,len(m)):\n",
    "        loc = m[i]\n",
    "        temp = pd.read_csv(analysis_endpt+loc+'.csv',skiprows=3)\n",
    "        temp.columns = ['Time','Speed_'+loc,'Direction_'+loc]\n",
    "        temp.set_index('Time',inplace=True)\n",
    "        df = df.merge(temp,how='left',on='Time')\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "    df.reset_index(inplace=True,drop=False)\n",
    "    df.to_csv(f'model_{model_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('model_1.csv')\n",
    "df2 = pd.read_csv('model_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('https://ai4impact.org/P003/historical/energy-ile-de-france.csv',header=None)\n",
    "target.columns = ['Time','Wind Energy']\n",
    "target.to_csv('target.csv',index=False)\n",
    "target['Time'] = pd.to_datetime(target['Time'])\n",
    "target.set_index('Time',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Speed_guitrancourt</th>\n",
       "      <th>Speed_lieusaint</th>\n",
       "      <th>Speed_lvs-pussay</th>\n",
       "      <th>Speed_parc-du-gatinais</th>\n",
       "      <th>Speed_arville</th>\n",
       "      <th>Speed_boissy-la-riviere</th>\n",
       "      <th>Speed_angerville-1</th>\n",
       "      <th>Speed_angerville-2</th>\n",
       "      <th>Direction_guitrancourt_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>Wind Energy</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Force</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020-08-17 20:00:00</td>\n",
       "      <td>1.731006</td>\n",
       "      <td>-0.771092</td>\n",
       "      <td>-0.848547</td>\n",
       "      <td>-1.168429</td>\n",
       "      <td>-0.792996</td>\n",
       "      <td>-0.825442</td>\n",
       "      <td>-1.100277</td>\n",
       "      <td>-1.157459</td>\n",
       "      <td>-1.157221</td>\n",
       "      <td>0.884412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.302649</td>\n",
       "      <td>-0.677287</td>\n",
       "      <td>-1.013626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-17 21:00:00</td>\n",
       "      <td>1.731115</td>\n",
       "      <td>-0.956090</td>\n",
       "      <td>-1.058139</td>\n",
       "      <td>-1.322526</td>\n",
       "      <td>-0.957032</td>\n",
       "      <td>-0.992304</td>\n",
       "      <td>-1.263382</td>\n",
       "      <td>-1.314476</td>\n",
       "      <td>-1.314195</td>\n",
       "      <td>0.861563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.433817</td>\n",
       "      <td>-0.691094</td>\n",
       "      <td>-0.946613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-17 22:00:00</td>\n",
       "      <td>1.731225</td>\n",
       "      <td>-1.112943</td>\n",
       "      <td>-1.194949</td>\n",
       "      <td>-1.371792</td>\n",
       "      <td>-1.035802</td>\n",
       "      <td>-1.070685</td>\n",
       "      <td>-1.320897</td>\n",
       "      <td>-1.366155</td>\n",
       "      <td>-1.365860</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.591219</td>\n",
       "      <td>-0.718709</td>\n",
       "      <td>-0.787457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-17 23:00:00</td>\n",
       "      <td>1.731334</td>\n",
       "      <td>-1.230406</td>\n",
       "      <td>-1.239387</td>\n",
       "      <td>-1.292701</td>\n",
       "      <td>-1.009725</td>\n",
       "      <td>-1.040206</td>\n",
       "      <td>-1.248675</td>\n",
       "      <td>-1.288803</td>\n",
       "      <td>-1.288529</td>\n",
       "      <td>0.700898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.564985</td>\n",
       "      <td>-0.276874</td>\n",
       "      <td>-0.284858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020-08-18 00:00:00</td>\n",
       "      <td>1.731443</td>\n",
       "      <td>-1.297234</td>\n",
       "      <td>-1.171861</td>\n",
       "      <td>-1.061727</td>\n",
       "      <td>-0.859221</td>\n",
       "      <td>-0.880484</td>\n",
       "      <td>-1.022571</td>\n",
       "      <td>-1.058726</td>\n",
       "      <td>-1.058514</td>\n",
       "      <td>0.545987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.315762</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>3.320789</td>\n",
       "      <td>-0.270112</td>\n",
       "      <td>-0.237064</td>\n",
       "      <td>0.247805</td>\n",
       "      <td>0.217741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0  Speed_guitrancourt  Speed_lieusaint  \\\n",
       "Time                                                                   \n",
       "2020-08-17 20:00:00    1.731006           -0.771092        -0.848547   \n",
       "2020-08-17 21:00:00    1.731115           -0.956090        -1.058139   \n",
       "2020-08-17 22:00:00    1.731225           -1.112943        -1.194949   \n",
       "2020-08-17 23:00:00    1.731334           -1.230406        -1.239387   \n",
       "2020-08-18 00:00:00    1.731443           -1.297234        -1.171861   \n",
       "\n",
       "                     Speed_lvs-pussay  Speed_parc-du-gatinais  Speed_arville  \\\n",
       "Time                                                                           \n",
       "2020-08-17 20:00:00         -1.168429               -0.792996      -0.825442   \n",
       "2020-08-17 21:00:00         -1.322526               -0.957032      -0.992304   \n",
       "2020-08-17 22:00:00         -1.371792               -1.035802      -1.070685   \n",
       "2020-08-17 23:00:00         -1.292701               -1.009725      -1.040206   \n",
       "2020-08-18 00:00:00         -1.061727               -0.859221      -0.880484   \n",
       "\n",
       "                     Speed_boissy-la-riviere  Speed_angerville-1  \\\n",
       "Time                                                               \n",
       "2020-08-17 20:00:00                -1.100277           -1.157459   \n",
       "2020-08-17 21:00:00                -1.263382           -1.314476   \n",
       "2020-08-17 22:00:00                -1.320897           -1.366155   \n",
       "2020-08-17 23:00:00                -1.248675           -1.288803   \n",
       "2020-08-18 00:00:00                -1.022571           -1.058726   \n",
       "\n",
       "                     Speed_angerville-2  Direction_guitrancourt_sin  ...  \\\n",
       "Time                                                                 ...   \n",
       "2020-08-17 20:00:00           -1.157221                    0.884412  ...   \n",
       "2020-08-17 21:00:00           -1.314195                    0.861563  ...   \n",
       "2020-08-17 22:00:00           -1.365860                    0.802920  ...   \n",
       "2020-08-17 23:00:00           -1.288529                    0.700898  ...   \n",
       "2020-08-18 00:00:00           -1.058514                    0.545987  ...   \n",
       "\n",
       "                      month_3   month_4   month_5   month_6   month_7  \\\n",
       "Time                                                                    \n",
       "2020-08-17 20:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-17 21:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-17 22:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-17 23:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "2020-08-18 00:00:00 -0.321516 -0.315762 -0.321516 -0.315762 -0.321516   \n",
       "\n",
       "                      month_8   month_9  Wind Energy  Momentum     Force  \n",
       "Time                                                                      \n",
       "2020-08-17 20:00:00  3.320789 -0.270112    -0.302649 -0.677287 -1.013626  \n",
       "2020-08-17 21:00:00  3.320789 -0.270112    -0.433817 -0.691094 -0.946613  \n",
       "2020-08-17 22:00:00  3.320789 -0.270112    -0.591219 -0.718709 -0.787457  \n",
       "2020-08-17 23:00:00  3.320789 -0.270112    -0.564985 -0.276874 -0.284858  \n",
       "2020-08-18 00:00:00  3.320789 -0.270112    -0.237064  0.247805  0.217741  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df1.copy()\n",
    "transformer = DataTransformer(df)\n",
    "transformer.transform()\n",
    "df = transformer.get_df()\n",
    "lagged = transformer.get_lagged_input()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31765, 64), (31765,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:,df.columns!='Wind Energy'].values\n",
    "y = df['Wind Energy'].values\n",
    "X = np.concatenate((X,lagged),axis=1)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19059, 62), (12706, 62), (19059,), (12706,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.4)\n",
    "x_train_features = x_train[:,:62]\n",
    "x_test_features = x_test[:,:62]\n",
    "x_train_lagged = x_train[:,62]\n",
    "x_test_lagged = x_test[:,62]\n",
    "x_train_features.shape,x_test_features.shape,x_train_lagged.shape,x_test_lagged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "def encoder(no_of_features, latent_dim = latent_dim):\n",
    "    features = Input(shape = (no_of_features,), name = 'Features')\n",
    "    X = Dense(62, activation = 'relu')(features)\n",
    "    X = Dense(32, activation = 'relu')(X)\n",
    "    LATENT = Dense(latent_dim, activation = 'relu')(X)\n",
    "    encoder = Model(features, LATENT, name = 'encoder')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(latent_dim = latent_dim):\n",
    "    LATENT_INPUTS = Input(shape = (latent_dim,))\n",
    "    X = Dense(32, activation = 'relu')(LATENT_INPUTS)\n",
    "    OUTPUTS = Dense(62, activation = 'linear')(X)\n",
    "    decoder = Model(LATENT_INPUTS, OUTPUTS, name = 'decoder')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference Model\n",
    "def create_model(latent_dim = latent_dim):\n",
    "    LATENT_INPUTS = Input(shape = (latent_dim,))\n",
    "    X = Dense(64,activation='relu')(LATENT_INPUTS)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(32,activation='relu')(X)\n",
    "    X = Dense(6,activation='relu')(X)\n",
    "\n",
    "    output = Dense(1,activation='linear')(X)\n",
    "    model = Model(inputs= LATENT_INPUTS ,outputs=[output,decoder], name = 'energy')\n",
    "    print(model.summary())\n",
    "    model.compile(loss={'energy': 'mse',\n",
    "                        'decoder': 'mae'},\n",
    "                  optimizer = 'adam')\n",
    "    plot_model(model,to_file='difference model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder(62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Features (InputLayer)        [(None, 62)]              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 62)                3906      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 32)                2016      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 6,450\n",
      "Trainable params: 6,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 62)                2046      \n",
      "=================================================================\n",
      "Total params: 2,590\n",
      "Trainable params: 2,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The first argument to `Layer.call` must always be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-a9b8d43e16e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-135-f690878a8d14>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(latent_dim)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mLATENT_INPUTS\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'energy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     model.compile(loss={'energy': 'mse',\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       raise ValueError(\n\u001b[1;32m--> 800\u001b[1;33m           'The first argument to `Layer.call` must always be passed.')\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[0mcall_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
     ]
    }
   ],
   "source": [
    "create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "def model():\n",
    "    #encoder\n",
    "    features = Input(shape=(62,),name='Features')\n",
    "    X = Dense(62, activation = 'relu')(features)\n",
    "    X1 = Dense(32, activation = 'relu')(X)\n",
    "    encoded = Dense(latent_dim, activation = 'relu', name = 'encoder')(X1)\n",
    "    \n",
    "    #difference model\n",
    "    X2 = Dense(32,activation='relu')(encoded)\n",
    "    X3 = Dropout(0.2)(X2)\n",
    "    X4 = Dense(6,activation='relu')(X3)\n",
    "    output = Dense(1, activation='linear', name = 'energy')(X4)\n",
    "    \n",
    "    #decoder \n",
    "    X5 = Dense(32, activation = 'relu')(encoded)\n",
    "    decoded = Dense(62, activation = 'linear', name = 'autoencoder')(X5)\n",
    "    \n",
    "    model = Model(inputs = features, outputs = [output, decoded])\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Features (InputLayer)           [(None, 62)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 62)           3906        Features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2016        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Dense)                 (None, 16)           528         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           544         encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            198         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           544         encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "energy (Dense)                  (None, 1)            7           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "autoencoder (Dense)             (None, 62)           2046        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,789\n",
      "Trainable params: 9,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss={'energy': 'mse', \n",
    "                    'autoencoder': 'mse'},\n",
    "              optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.4110 - energy_loss: 0.1224 - autoencoder_loss: 0.2886 - val_loss: 0.4246 - val_energy_loss: 0.1365 - val_autoencoder_loss: 0.2881\n",
      "Epoch 2/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.4011 - energy_loss: 0.1182 - autoencoder_loss: 0.2829 - val_loss: 0.4236 - val_energy_loss: 0.1415 - val_autoencoder_loss: 0.2822\n",
      "Epoch 3/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3928 - energy_loss: 0.1148 - autoencoder_loss: 0.2780 - val_loss: 0.4132 - val_energy_loss: 0.1350 - val_autoencoder_loss: 0.2783\n",
      "Epoch 4/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3884 - energy_loss: 0.1134 - autoencoder_loss: 0.2749 - val_loss: 0.3990 - val_energy_loss: 0.1230 - val_autoencoder_loss: 0.2759\n",
      "Epoch 5/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3831 - energy_loss: 0.1110 - autoencoder_loss: 0.2721 - val_loss: 0.4264 - val_energy_loss: 0.1528 - val_autoencoder_loss: 0.2736\n",
      "Epoch 6/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3787 - energy_loss: 0.1087 - autoencoder_loss: 0.2701 - val_loss: 0.3950 - val_energy_loss: 0.1221 - val_autoencoder_loss: 0.2729\n",
      "Epoch 7/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3749 - energy_loss: 0.1067 - autoencoder_loss: 0.2683 - val_loss: 0.3904 - val_energy_loss: 0.1196 - val_autoencoder_loss: 0.2709\n",
      "Epoch 8/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3724 - energy_loss: 0.1057 - autoencoder_loss: 0.2667 - val_loss: 0.3942 - val_energy_loss: 0.1222 - val_autoencoder_loss: 0.2720\n",
      "Epoch 9/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3703 - energy_loss: 0.1050 - autoencoder_loss: 0.2654 - val_loss: 0.3994 - val_energy_loss: 0.1316 - val_autoencoder_loss: 0.2678\n",
      "Epoch 10/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3658 - energy_loss: 0.1017 - autoencoder_loss: 0.2640 - val_loss: 0.3905 - val_energy_loss: 0.1240 - val_autoencoder_loss: 0.2665\n",
      "Epoch 11/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3642 - energy_loss: 0.1010 - autoencoder_loss: 0.2632 - val_loss: 0.3995 - val_energy_loss: 0.1337 - val_autoencoder_loss: 0.2658\n",
      "Epoch 12/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3629 - energy_loss: 0.1004 - autoencoder_loss: 0.2624 - val_loss: 0.3781 - val_energy_loss: 0.1130 - val_autoencoder_loss: 0.2651\n",
      "Epoch 13/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3606 - energy_loss: 0.0991 - autoencoder_loss: 0.2616 - val_loss: 0.3990 - val_energy_loss: 0.1345 - val_autoencoder_loss: 0.2645\n",
      "Epoch 14/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3622 - energy_loss: 0.1007 - autoencoder_loss: 0.2615 - val_loss: 0.3878 - val_energy_loss: 0.1251 - val_autoencoder_loss: 0.2628\n",
      "Epoch 15/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3594 - energy_loss: 0.0990 - autoencoder_loss: 0.2605 - val_loss: 0.4082 - val_energy_loss: 0.1451 - val_autoencoder_loss: 0.2631\n",
      "Epoch 16/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3563 - energy_loss: 0.0964 - autoencoder_loss: 0.2599 - val_loss: 0.3856 - val_energy_loss: 0.1229 - val_autoencoder_loss: 0.2627\n",
      "Epoch 17/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3569 - energy_loss: 0.0972 - autoencoder_loss: 0.2596 - val_loss: 0.3934 - val_energy_loss: 0.1314 - val_autoencoder_loss: 0.2620\n",
      "Epoch 18/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3540 - energy_loss: 0.0948 - autoencoder_loss: 0.2591 - val_loss: 0.3871 - val_energy_loss: 0.1260 - val_autoencoder_loss: 0.2611\n",
      "Epoch 19/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3517 - energy_loss: 0.0934 - autoencoder_loss: 0.2584 - val_loss: 0.3866 - val_energy_loss: 0.1261 - val_autoencoder_loss: 0.2604\n",
      "Epoch 20/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3530 - energy_loss: 0.0950 - autoencoder_loss: 0.2580 - val_loss: 0.3935 - val_energy_loss: 0.1318 - val_autoencoder_loss: 0.2617\n",
      "Epoch 21/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3502 - energy_loss: 0.0925 - autoencoder_loss: 0.2577 - val_loss: 0.3830 - val_energy_loss: 0.1216 - val_autoencoder_loss: 0.2614\n",
      "Epoch 22/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3508 - energy_loss: 0.0932 - autoencoder_loss: 0.2576 - val_loss: 0.3881 - val_energy_loss: 0.1268 - val_autoencoder_loss: 0.2613\n",
      "Epoch 23/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3491 - energy_loss: 0.0920 - autoencoder_loss: 0.2571 - val_loss: 0.3835 - val_energy_loss: 0.1222 - val_autoencoder_loss: 0.2614\n",
      "Epoch 24/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3485 - energy_loss: 0.0914 - autoencoder_loss: 0.2571 - val_loss: 0.3871 - val_energy_loss: 0.1272 - val_autoencoder_loss: 0.2600\n",
      "Epoch 25/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3479 - energy_loss: 0.0911 - autoencoder_loss: 0.2568 - val_loss: 0.3979 - val_energy_loss: 0.1370 - val_autoencoder_loss: 0.2609\n",
      "Epoch 26/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3469 - energy_loss: 0.0906 - autoencoder_loss: 0.2564 - val_loss: 0.3790 - val_energy_loss: 0.1187 - val_autoencoder_loss: 0.2603\n",
      "Epoch 27/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3464 - energy_loss: 0.0900 - autoencoder_loss: 0.2564 - val_loss: 0.3922 - val_energy_loss: 0.1321 - val_autoencoder_loss: 0.2602\n",
      "Epoch 28/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3460 - energy_loss: 0.0898 - autoencoder_loss: 0.2562 - val_loss: 0.3956 - val_energy_loss: 0.1356 - val_autoencoder_loss: 0.2600\n",
      "Epoch 29/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3447 - energy_loss: 0.0890 - autoencoder_loss: 0.2557 - val_loss: 0.3915 - val_energy_loss: 0.1325 - val_autoencoder_loss: 0.2591\n",
      "Epoch 30/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3440 - energy_loss: 0.0882 - autoencoder_loss: 0.2558 - val_loss: 0.3883 - val_energy_loss: 0.1290 - val_autoencoder_loss: 0.2593\n",
      "Epoch 31/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3438 - energy_loss: 0.0886 - autoencoder_loss: 0.2552 - val_loss: 0.3773 - val_energy_loss: 0.1176 - val_autoencoder_loss: 0.2598\n",
      "Epoch 32/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3421 - energy_loss: 0.0889 - autoencoder_loss: 0.2532 - val_loss: 0.3818 - val_energy_loss: 0.1271 - val_autoencoder_loss: 0.2547\n",
      "Epoch 33/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3347 - energy_loss: 0.0876 - autoencoder_loss: 0.2471 - val_loss: 0.3882 - val_energy_loss: 0.1406 - val_autoencoder_loss: 0.2476\n",
      "Epoch 34/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3284 - energy_loss: 0.0867 - autoencoder_loss: 0.2417 - val_loss: 0.3859 - val_energy_loss: 0.1411 - val_autoencoder_loss: 0.2448\n",
      "Epoch 35/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3270 - energy_loss: 0.0871 - autoencoder_loss: 0.2399 - val_loss: 0.3675 - val_energy_loss: 0.1234 - val_autoencoder_loss: 0.2440\n",
      "Epoch 36/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3256 - energy_loss: 0.0862 - autoencoder_loss: 0.2394 - val_loss: 0.3784 - val_energy_loss: 0.1362 - val_autoencoder_loss: 0.2422\n",
      "Epoch 37/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3263 - energy_loss: 0.0871 - autoencoder_loss: 0.2392 - val_loss: 0.3688 - val_energy_loss: 0.1262 - val_autoencoder_loss: 0.2427\n",
      "Epoch 38/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3251 - energy_loss: 0.0862 - autoencoder_loss: 0.2389 - val_loss: 0.3916 - val_energy_loss: 0.1495 - val_autoencoder_loss: 0.2420\n",
      "Epoch 39/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3239 - energy_loss: 0.0855 - autoencoder_loss: 0.2384 - val_loss: 0.3578 - val_energy_loss: 0.1147 - val_autoencoder_loss: 0.2431\n",
      "Epoch 40/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3235 - energy_loss: 0.0850 - autoencoder_loss: 0.2385 - val_loss: 0.3686 - val_energy_loss: 0.1270 - val_autoencoder_loss: 0.2416\n",
      "Epoch 41/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3235 - energy_loss: 0.0854 - autoencoder_loss: 0.2381 - val_loss: 0.3642 - val_energy_loss: 0.1225 - val_autoencoder_loss: 0.2417\n",
      "Epoch 42/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3232 - energy_loss: 0.0851 - autoencoder_loss: 0.2380 - val_loss: 0.3570 - val_energy_loss: 0.1155 - val_autoencoder_loss: 0.2415\n",
      "Epoch 43/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3223 - energy_loss: 0.0844 - autoencoder_loss: 0.2379 - val_loss: 0.3665 - val_energy_loss: 0.1252 - val_autoencoder_loss: 0.2413\n",
      "Epoch 44/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3209 - energy_loss: 0.0832 - autoencoder_loss: 0.2377 - val_loss: 0.3572 - val_energy_loss: 0.1143 - val_autoencoder_loss: 0.2429\n",
      "Epoch 45/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3209 - energy_loss: 0.0832 - autoencoder_loss: 0.2377 - val_loss: 0.3769 - val_energy_loss: 0.1351 - val_autoencoder_loss: 0.2418\n",
      "Epoch 46/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3212 - energy_loss: 0.0835 - autoencoder_loss: 0.2377 - val_loss: 0.3768 - val_energy_loss: 0.1351 - val_autoencoder_loss: 0.2417\n",
      "Epoch 47/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3202 - energy_loss: 0.0828 - autoencoder_loss: 0.2374 - val_loss: 0.3602 - val_energy_loss: 0.1188 - val_autoencoder_loss: 0.2414\n",
      "Epoch 48/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3186 - energy_loss: 0.0812 - autoencoder_loss: 0.2375 - val_loss: 0.3671 - val_energy_loss: 0.1255 - val_autoencoder_loss: 0.2415\n",
      "Epoch 49/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3207 - energy_loss: 0.0835 - autoencoder_loss: 0.2373 - val_loss: 0.3549 - val_energy_loss: 0.1137 - val_autoencoder_loss: 0.2413\n",
      "Epoch 50/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3201 - energy_loss: 0.0828 - autoencoder_loss: 0.2373 - val_loss: 0.3473 - val_energy_loss: 0.1066 - val_autoencoder_loss: 0.2407\n",
      "Epoch 51/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3192 - energy_loss: 0.0820 - autoencoder_loss: 0.2372 - val_loss: 0.3657 - val_energy_loss: 0.1252 - val_autoencoder_loss: 0.2405\n",
      "Epoch 52/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3177 - energy_loss: 0.0807 - autoencoder_loss: 0.2370 - val_loss: 0.3586 - val_energy_loss: 0.1174 - val_autoencoder_loss: 0.2412\n",
      "Epoch 53/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3197 - energy_loss: 0.0826 - autoencoder_loss: 0.2371 - val_loss: 0.3552 - val_energy_loss: 0.1136 - val_autoencoder_loss: 0.2416\n",
      "Epoch 54/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3188 - energy_loss: 0.0821 - autoencoder_loss: 0.2367 - val_loss: 0.3610 - val_energy_loss: 0.1200 - val_autoencoder_loss: 0.2410\n",
      "Epoch 55/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3161 - energy_loss: 0.0803 - autoencoder_loss: 0.2358 - val_loss: 0.3566 - val_energy_loss: 0.1176 - val_autoencoder_loss: 0.2390\n",
      "Epoch 56/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3141 - energy_loss: 0.0812 - autoencoder_loss: 0.2328 - val_loss: 0.3648 - val_energy_loss: 0.1308 - val_autoencoder_loss: 0.2341\n",
      "Epoch 57/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3063 - energy_loss: 0.0805 - autoencoder_loss: 0.2258 - val_loss: 0.3580 - val_energy_loss: 0.1318 - val_autoencoder_loss: 0.2261\n",
      "Epoch 58/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3035 - energy_loss: 0.0814 - autoencoder_loss: 0.2221 - val_loss: 0.3496 - val_energy_loss: 0.1242 - val_autoencoder_loss: 0.2254\n",
      "Epoch 59/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3005 - energy_loss: 0.0794 - autoencoder_loss: 0.2211 - val_loss: 0.3616 - val_energy_loss: 0.1368 - val_autoencoder_loss: 0.2249\n",
      "Epoch 60/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3012 - energy_loss: 0.0805 - autoencoder_loss: 0.2208 - val_loss: 0.3507 - val_energy_loss: 0.1266 - val_autoencoder_loss: 0.2241\n",
      "Epoch 61/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2990 - energy_loss: 0.0785 - autoencoder_loss: 0.2204 - val_loss: 0.3484 - val_energy_loss: 0.1237 - val_autoencoder_loss: 0.2247\n",
      "Epoch 62/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3005 - energy_loss: 0.0799 - autoencoder_loss: 0.2206 - val_loss: 0.3829 - val_energy_loss: 0.1591 - val_autoencoder_loss: 0.2238\n",
      "Epoch 63/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3000 - energy_loss: 0.0799 - autoencoder_loss: 0.2201 - val_loss: 0.3479 - val_energy_loss: 0.1238 - val_autoencoder_loss: 0.2241\n",
      "Epoch 64/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2980 - energy_loss: 0.0780 - autoencoder_loss: 0.2200 - val_loss: 0.3556 - val_energy_loss: 0.1308 - val_autoencoder_loss: 0.2248\n",
      "Epoch 65/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.3000 - energy_loss: 0.0799 - autoencoder_loss: 0.2201 - val_loss: 0.3588 - val_energy_loss: 0.1342 - val_autoencoder_loss: 0.2246\n",
      "Epoch 66/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2984 - energy_loss: 0.0785 - autoencoder_loss: 0.2199 - val_loss: 0.3347 - val_energy_loss: 0.1110 - val_autoencoder_loss: 0.2237\n",
      "Epoch 67/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2983 - energy_loss: 0.0784 - autoencoder_loss: 0.2199 - val_loss: 0.3507 - val_energy_loss: 0.1259 - val_autoencoder_loss: 0.2247\n",
      "Epoch 68/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2976 - energy_loss: 0.0777 - autoencoder_loss: 0.2199 - val_loss: 0.3411 - val_energy_loss: 0.1152 - val_autoencoder_loss: 0.2259\n",
      "Epoch 69/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2974 - energy_loss: 0.0778 - autoencoder_loss: 0.2196 - val_loss: 0.3441 - val_energy_loss: 0.1197 - val_autoencoder_loss: 0.2244\n",
      "Epoch 70/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2973 - energy_loss: 0.0777 - autoencoder_loss: 0.2196 - val_loss: 0.3490 - val_energy_loss: 0.1249 - val_autoencoder_loss: 0.2241\n",
      "Epoch 71/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2986 - energy_loss: 0.0792 - autoencoder_loss: 0.2194 - val_loss: 0.3456 - val_energy_loss: 0.1217 - val_autoencoder_loss: 0.2239\n",
      "Epoch 72/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2951 - energy_loss: 0.0761 - autoencoder_loss: 0.2190 - val_loss: 0.3601 - val_energy_loss: 0.1362 - val_autoencoder_loss: 0.2239\n",
      "Epoch 73/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2958 - energy_loss: 0.0773 - autoencoder_loss: 0.2186 - val_loss: 0.3422 - val_energy_loss: 0.1181 - val_autoencoder_loss: 0.2241\n",
      "Epoch 74/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2940 - energy_loss: 0.0764 - autoencoder_loss: 0.2176 - val_loss: 0.3311 - val_energy_loss: 0.1103 - val_autoencoder_loss: 0.2208\n",
      "Epoch 75/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2929 - energy_loss: 0.0775 - autoencoder_loss: 0.2154 - val_loss: 0.3528 - val_energy_loss: 0.1341 - val_autoencoder_loss: 0.2187\n",
      "Epoch 76/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2889 - energy_loss: 0.0768 - autoencoder_loss: 0.2121 - val_loss: 0.3271 - val_energy_loss: 0.1108 - val_autoencoder_loss: 0.2162\n",
      "Epoch 77/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2859 - energy_loss: 0.0774 - autoencoder_loss: 0.2085 - val_loss: 0.3245 - val_energy_loss: 0.1137 - val_autoencoder_loss: 0.2108\n",
      "Epoch 78/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2818 - energy_loss: 0.0761 - autoencoder_loss: 0.2057 - val_loss: 0.3431 - val_energy_loss: 0.1336 - val_autoencoder_loss: 0.2096\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2812 - energy_loss: 0.0765 - autoencoder_loss: 0.2047 - val_loss: 0.3323 - val_energy_loss: 0.1247 - val_autoencoder_loss: 0.2077\n",
      "Epoch 80/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2796 - energy_loss: 0.0759 - autoencoder_loss: 0.2037 - val_loss: 0.3603 - val_energy_loss: 0.1513 - val_autoencoder_loss: 0.2090\n",
      "Epoch 81/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2794 - energy_loss: 0.0761 - autoencoder_loss: 0.2033 - val_loss: 0.3292 - val_energy_loss: 0.1223 - val_autoencoder_loss: 0.2069\n",
      "Epoch 82/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2795 - energy_loss: 0.0765 - autoencoder_loss: 0.2030 - val_loss: 0.3141 - val_energy_loss: 0.1076 - val_autoencoder_loss: 0.2065\n",
      "Epoch 83/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2771 - energy_loss: 0.0747 - autoencoder_loss: 0.2025 - val_loss: 0.3402 - val_energy_loss: 0.1334 - val_autoencoder_loss: 0.2067\n",
      "Epoch 84/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2774 - energy_loss: 0.0750 - autoencoder_loss: 0.2024 - val_loss: 0.3269 - val_energy_loss: 0.1196 - val_autoencoder_loss: 0.2073\n",
      "Epoch 85/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2774 - energy_loss: 0.0751 - autoencoder_loss: 0.2024 - val_loss: 0.3180 - val_energy_loss: 0.1113 - val_autoencoder_loss: 0.2067\n",
      "Epoch 86/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2776 - energy_loss: 0.0753 - autoencoder_loss: 0.2023 - val_loss: 0.3178 - val_energy_loss: 0.1117 - val_autoencoder_loss: 0.2061\n",
      "Epoch 87/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2775 - energy_loss: 0.0753 - autoencoder_loss: 0.2023 - val_loss: 0.3194 - val_energy_loss: 0.1127 - val_autoencoder_loss: 0.2067\n",
      "Epoch 88/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2764 - energy_loss: 0.0745 - autoencoder_loss: 0.2020 - val_loss: 0.3239 - val_energy_loss: 0.1161 - val_autoencoder_loss: 0.2078\n",
      "Epoch 89/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2764 - energy_loss: 0.0746 - autoencoder_loss: 0.2018 - val_loss: 0.3113 - val_energy_loss: 0.1054 - val_autoencoder_loss: 0.2059\n",
      "Epoch 90/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2774 - energy_loss: 0.0755 - autoencoder_loss: 0.2020 - val_loss: 0.3126 - val_energy_loss: 0.1051 - val_autoencoder_loss: 0.2075\n",
      "Epoch 91/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2750 - energy_loss: 0.0733 - autoencoder_loss: 0.2016 - val_loss: 0.3169 - val_energy_loss: 0.1103 - val_autoencoder_loss: 0.2065\n",
      "Epoch 92/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2744 - energy_loss: 0.0729 - autoencoder_loss: 0.2015 - val_loss: 0.3171 - val_energy_loss: 0.1106 - val_autoencoder_loss: 0.2064\n",
      "Epoch 93/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2756 - energy_loss: 0.0742 - autoencoder_loss: 0.2014 - val_loss: 0.3252 - val_energy_loss: 0.1181 - val_autoencoder_loss: 0.2071\n",
      "Epoch 94/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2764 - energy_loss: 0.0749 - autoencoder_loss: 0.2014 - val_loss: 0.3237 - val_energy_loss: 0.1162 - val_autoencoder_loss: 0.2075\n",
      "Epoch 95/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2740 - energy_loss: 0.0727 - autoencoder_loss: 0.2013 - val_loss: 0.3249 - val_energy_loss: 0.1179 - val_autoencoder_loss: 0.2069\n",
      "Epoch 96/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2743 - energy_loss: 0.0729 - autoencoder_loss: 0.2014 - val_loss: 0.3258 - val_energy_loss: 0.1192 - val_autoencoder_loss: 0.2066\n",
      "Epoch 97/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2743 - energy_loss: 0.0730 - autoencoder_loss: 0.2013 - val_loss: 0.3464 - val_energy_loss: 0.1395 - val_autoencoder_loss: 0.2069\n",
      "Epoch 98/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2739 - energy_loss: 0.0729 - autoencoder_loss: 0.2011 - val_loss: 0.3298 - val_energy_loss: 0.1239 - val_autoencoder_loss: 0.2059\n",
      "Epoch 99/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2730 - energy_loss: 0.0720 - autoencoder_loss: 0.2009 - val_loss: 0.3235 - val_energy_loss: 0.1166 - val_autoencoder_loss: 0.2069\n",
      "Epoch 100/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2724 - energy_loss: 0.0712 - autoencoder_loss: 0.2011 - val_loss: 0.3191 - val_energy_loss: 0.1128 - val_autoencoder_loss: 0.2063\n",
      "Epoch 101/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2733 - energy_loss: 0.0724 - autoencoder_loss: 0.2010 - val_loss: 0.3250 - val_energy_loss: 0.1194 - val_autoencoder_loss: 0.2055\n",
      "Epoch 102/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2736 - energy_loss: 0.0726 - autoencoder_loss: 0.2010 - val_loss: 0.3139 - val_energy_loss: 0.1084 - val_autoencoder_loss: 0.2056\n",
      "Epoch 103/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2723 - energy_loss: 0.0714 - autoencoder_loss: 0.2009 - val_loss: 0.3287 - val_energy_loss: 0.1235 - val_autoencoder_loss: 0.2052\n",
      "Epoch 104/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2737 - energy_loss: 0.0725 - autoencoder_loss: 0.2012 - val_loss: 0.3253 - val_energy_loss: 0.1198 - val_autoencoder_loss: 0.2054\n",
      "Epoch 105/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2731 - energy_loss: 0.0722 - autoencoder_loss: 0.2008 - val_loss: 0.3155 - val_energy_loss: 0.1102 - val_autoencoder_loss: 0.2052\n",
      "Epoch 106/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2728 - energy_loss: 0.0719 - autoencoder_loss: 0.2009 - val_loss: 0.3178 - val_energy_loss: 0.1119 - val_autoencoder_loss: 0.2059\n",
      "Epoch 107/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2725 - energy_loss: 0.0718 - autoencoder_loss: 0.2007 - val_loss: 0.3254 - val_energy_loss: 0.1199 - val_autoencoder_loss: 0.2055\n",
      "Epoch 108/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2716 - energy_loss: 0.0711 - autoencoder_loss: 0.2005 - val_loss: 0.3285 - val_energy_loss: 0.1230 - val_autoencoder_loss: 0.2055\n",
      "Epoch 109/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2711 - energy_loss: 0.0704 - autoencoder_loss: 0.2007 - val_loss: 0.3314 - val_energy_loss: 0.1255 - val_autoencoder_loss: 0.2059\n",
      "Epoch 110/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2723 - energy_loss: 0.0716 - autoencoder_loss: 0.2008 - val_loss: 0.3101 - val_energy_loss: 0.1030 - val_autoencoder_loss: 0.2071\n",
      "Epoch 111/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2726 - energy_loss: 0.0719 - autoencoder_loss: 0.2006 - val_loss: 0.3270 - val_energy_loss: 0.1218 - val_autoencoder_loss: 0.2053\n",
      "Epoch 112/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2723 - energy_loss: 0.0715 - autoencoder_loss: 0.2008 - val_loss: 0.3183 - val_energy_loss: 0.1114 - val_autoencoder_loss: 0.2070\n",
      "Epoch 113/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2714 - energy_loss: 0.0708 - autoencoder_loss: 0.2006 - val_loss: 0.3294 - val_energy_loss: 0.1245 - val_autoencoder_loss: 0.2049\n",
      "Epoch 114/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2711 - energy_loss: 0.0705 - autoencoder_loss: 0.2005 - val_loss: 0.3312 - val_energy_loss: 0.1259 - val_autoencoder_loss: 0.2053\n",
      "Epoch 115/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2705 - energy_loss: 0.0699 - autoencoder_loss: 0.2007 - val_loss: 0.3308 - val_energy_loss: 0.1249 - val_autoencoder_loss: 0.2059\n",
      "Epoch 116/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2707 - energy_loss: 0.0704 - autoencoder_loss: 0.2003 - val_loss: 0.3284 - val_energy_loss: 0.1231 - val_autoencoder_loss: 0.2053\n",
      "Epoch 117/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2704 - energy_loss: 0.0701 - autoencoder_loss: 0.2004 - val_loss: 0.3169 - val_energy_loss: 0.1108 - val_autoencoder_loss: 0.2061\n",
      "Epoch 118/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2708 - energy_loss: 0.0704 - autoencoder_loss: 0.2004 - val_loss: 0.3174 - val_energy_loss: 0.1112 - val_autoencoder_loss: 0.2063\n",
      "Epoch 119/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2716 - energy_loss: 0.0713 - autoencoder_loss: 0.2003 - val_loss: 0.3344 - val_energy_loss: 0.1293 - val_autoencoder_loss: 0.2051\n",
      "Epoch 120/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2696 - energy_loss: 0.0699 - autoencoder_loss: 0.1997 - val_loss: 0.3130 - val_energy_loss: 0.1076 - val_autoencoder_loss: 0.2054\n",
      "Epoch 121/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2678 - energy_loss: 0.0691 - autoencoder_loss: 0.1988 - val_loss: 0.3255 - val_energy_loss: 0.1217 - val_autoencoder_loss: 0.2037\n",
      "Epoch 122/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2672 - energy_loss: 0.0698 - autoencoder_loss: 0.1974 - val_loss: 0.3137 - val_energy_loss: 0.1129 - val_autoencoder_loss: 0.2008\n",
      "Epoch 123/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2646 - energy_loss: 0.0693 - autoencoder_loss: 0.1953 - val_loss: 0.3142 - val_energy_loss: 0.1149 - val_autoencoder_loss: 0.1994\n",
      "Epoch 124/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2627 - energy_loss: 0.0698 - autoencoder_loss: 0.1929 - val_loss: 0.3283 - val_energy_loss: 0.1313 - val_autoencoder_loss: 0.1970\n",
      "Epoch 125/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2598 - energy_loss: 0.0691 - autoencoder_loss: 0.1907 - val_loss: 0.3108 - val_energy_loss: 0.1148 - val_autoencoder_loss: 0.1961\n",
      "Epoch 126/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2593 - energy_loss: 0.0699 - autoencoder_loss: 0.1895 - val_loss: 0.3187 - val_energy_loss: 0.1243 - val_autoencoder_loss: 0.1944\n",
      "Epoch 127/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2582 - energy_loss: 0.0697 - autoencoder_loss: 0.1885 - val_loss: 0.3176 - val_energy_loss: 0.1247 - val_autoencoder_loss: 0.1929\n",
      "Epoch 128/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2564 - energy_loss: 0.0688 - autoencoder_loss: 0.1877 - val_loss: 0.3131 - val_energy_loss: 0.1199 - val_autoencoder_loss: 0.1932\n",
      "Epoch 129/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2560 - energy_loss: 0.0688 - autoencoder_loss: 0.1872 - val_loss: 0.3055 - val_energy_loss: 0.1127 - val_autoencoder_loss: 0.1928\n",
      "Epoch 130/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2557 - energy_loss: 0.0688 - autoencoder_loss: 0.1868 - val_loss: 0.3043 - val_energy_loss: 0.1116 - val_autoencoder_loss: 0.1928\n",
      "Epoch 131/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2558 - energy_loss: 0.0693 - autoencoder_loss: 0.1865 - val_loss: 0.3134 - val_energy_loss: 0.1215 - val_autoencoder_loss: 0.1918\n",
      "Epoch 132/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2558 - energy_loss: 0.0693 - autoencoder_loss: 0.1865 - val_loss: 0.3003 - val_energy_loss: 0.1090 - val_autoencoder_loss: 0.1913\n",
      "Epoch 133/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2553 - energy_loss: 0.0690 - autoencoder_loss: 0.1862 - val_loss: 0.3086 - val_energy_loss: 0.1178 - val_autoencoder_loss: 0.1909\n",
      "Epoch 134/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2549 - energy_loss: 0.0687 - autoencoder_loss: 0.1862 - val_loss: 0.3006 - val_energy_loss: 0.1093 - val_autoencoder_loss: 0.1913\n",
      "Epoch 135/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2549 - energy_loss: 0.0689 - autoencoder_loss: 0.1861 - val_loss: 0.3008 - val_energy_loss: 0.1097 - val_autoencoder_loss: 0.1911\n",
      "Epoch 136/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2545 - energy_loss: 0.0686 - autoencoder_loss: 0.1859 - val_loss: 0.3257 - val_energy_loss: 0.1345 - val_autoencoder_loss: 0.1913\n",
      "Epoch 137/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2536 - energy_loss: 0.0679 - autoencoder_loss: 0.1857 - val_loss: 0.3075 - val_energy_loss: 0.1170 - val_autoencoder_loss: 0.1905\n",
      "Epoch 138/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2532 - energy_loss: 0.0675 - autoencoder_loss: 0.1857 - val_loss: 0.3084 - val_energy_loss: 0.1175 - val_autoencoder_loss: 0.1909\n",
      "Epoch 139/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2532 - energy_loss: 0.0677 - autoencoder_loss: 0.1855 - val_loss: 0.2999 - val_energy_loss: 0.1082 - val_autoencoder_loss: 0.1916\n",
      "Epoch 140/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2542 - energy_loss: 0.0685 - autoencoder_loss: 0.1857 - val_loss: 0.3024 - val_energy_loss: 0.1119 - val_autoencoder_loss: 0.1905\n",
      "Epoch 141/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2538 - energy_loss: 0.0684 - autoencoder_loss: 0.1854 - val_loss: 0.3094 - val_energy_loss: 0.1189 - val_autoencoder_loss: 0.1905\n",
      "Epoch 142/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2526 - energy_loss: 0.0672 - autoencoder_loss: 0.1854 - val_loss: 0.3043 - val_energy_loss: 0.1141 - val_autoencoder_loss: 0.1902\n",
      "Epoch 143/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2529 - energy_loss: 0.0676 - autoencoder_loss: 0.1853 - val_loss: 0.3052 - val_energy_loss: 0.1149 - val_autoencoder_loss: 0.1903\n",
      "Epoch 144/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2533 - energy_loss: 0.0680 - autoencoder_loss: 0.1852 - val_loss: 0.3055 - val_energy_loss: 0.1161 - val_autoencoder_loss: 0.1894\n",
      "Epoch 145/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2532 - energy_loss: 0.0681 - autoencoder_loss: 0.1850 - val_loss: 0.2992 - val_energy_loss: 0.1096 - val_autoencoder_loss: 0.1896\n",
      "Epoch 146/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2523 - energy_loss: 0.0673 - autoencoder_loss: 0.1851 - val_loss: 0.3019 - val_energy_loss: 0.1117 - val_autoencoder_loss: 0.1901\n",
      "Epoch 147/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2528 - energy_loss: 0.0677 - autoencoder_loss: 0.1851 - val_loss: 0.3008 - val_energy_loss: 0.1110 - val_autoencoder_loss: 0.1898\n",
      "Epoch 148/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2523 - energy_loss: 0.0674 - autoencoder_loss: 0.1849 - val_loss: 0.2999 - val_energy_loss: 0.1107 - val_autoencoder_loss: 0.1891\n",
      "Epoch 149/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2528 - energy_loss: 0.0678 - autoencoder_loss: 0.1850 - val_loss: 0.3126 - val_energy_loss: 0.1225 - val_autoencoder_loss: 0.1901\n",
      "Epoch 150/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2526 - energy_loss: 0.0676 - autoencoder_loss: 0.1850 - val_loss: 0.3028 - val_energy_loss: 0.1141 - val_autoencoder_loss: 0.1887\n",
      "Epoch 151/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2514 - energy_loss: 0.0666 - autoencoder_loss: 0.1848 - val_loss: 0.2939 - val_energy_loss: 0.1045 - val_autoencoder_loss: 0.1894\n",
      "Epoch 152/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2522 - energy_loss: 0.0673 - autoencoder_loss: 0.1849 - val_loss: 0.3017 - val_energy_loss: 0.1123 - val_autoencoder_loss: 0.1893\n",
      "Epoch 153/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2521 - energy_loss: 0.0672 - autoencoder_loss: 0.1849 - val_loss: 0.3142 - val_energy_loss: 0.1250 - val_autoencoder_loss: 0.1893\n",
      "Epoch 154/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2514 - energy_loss: 0.0664 - autoencoder_loss: 0.1849 - val_loss: 0.3002 - val_energy_loss: 0.1108 - val_autoencoder_loss: 0.1894\n",
      "Epoch 155/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2514 - energy_loss: 0.0666 - autoencoder_loss: 0.1849 - val_loss: 0.3049 - val_energy_loss: 0.1157 - val_autoencoder_loss: 0.1893\n",
      "Epoch 156/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2525 - energy_loss: 0.0676 - autoencoder_loss: 0.1849 - val_loss: 0.2992 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1900\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2524 - energy_loss: 0.0676 - autoencoder_loss: 0.1848 - val_loss: 0.3079 - val_energy_loss: 0.1186 - val_autoencoder_loss: 0.1893\n",
      "Epoch 158/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2500 - energy_loss: 0.0655 - autoencoder_loss: 0.1845 - val_loss: 0.3026 - val_energy_loss: 0.1132 - val_autoencoder_loss: 0.1894\n",
      "Epoch 159/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2512 - energy_loss: 0.0662 - autoencoder_loss: 0.1850 - val_loss: 0.2953 - val_energy_loss: 0.1062 - val_autoencoder_loss: 0.1891\n",
      "Epoch 160/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2512 - energy_loss: 0.0666 - autoencoder_loss: 0.1846 - val_loss: 0.2928 - val_energy_loss: 0.1036 - val_autoencoder_loss: 0.1892\n",
      "Epoch 161/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2508 - energy_loss: 0.0662 - autoencoder_loss: 0.1846 - val_loss: 0.2996 - val_energy_loss: 0.1107 - val_autoencoder_loss: 0.1889\n",
      "Epoch 162/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2505 - energy_loss: 0.0659 - autoencoder_loss: 0.1845 - val_loss: 0.3362 - val_energy_loss: 0.1457 - val_autoencoder_loss: 0.1905\n",
      "Epoch 163/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2499 - energy_loss: 0.0656 - autoencoder_loss: 0.1843 - val_loss: 0.3147 - val_energy_loss: 0.1255 - val_autoencoder_loss: 0.1892\n",
      "Epoch 164/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2513 - energy_loss: 0.0666 - autoencoder_loss: 0.1847 - val_loss: 0.2977 - val_energy_loss: 0.1086 - val_autoencoder_loss: 0.1891\n",
      "Epoch 165/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2509 - energy_loss: 0.0664 - autoencoder_loss: 0.1845 - val_loss: 0.2994 - val_energy_loss: 0.1104 - val_autoencoder_loss: 0.1891\n",
      "Epoch 166/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2509 - energy_loss: 0.0664 - autoencoder_loss: 0.1845 - val_loss: 0.2981 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1889\n",
      "Epoch 167/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2499 - energy_loss: 0.0655 - autoencoder_loss: 0.1844 - val_loss: 0.3054 - val_energy_loss: 0.1155 - val_autoencoder_loss: 0.1899\n",
      "Epoch 168/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2495 - energy_loss: 0.0651 - autoencoder_loss: 0.1844 - val_loss: 0.3011 - val_energy_loss: 0.1111 - val_autoencoder_loss: 0.1900\n",
      "Epoch 169/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2496 - energy_loss: 0.0652 - autoencoder_loss: 0.1843 - val_loss: 0.3255 - val_energy_loss: 0.1355 - val_autoencoder_loss: 0.1900\n",
      "Epoch 170/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2498 - energy_loss: 0.0654 - autoencoder_loss: 0.1843 - val_loss: 0.2948 - val_energy_loss: 0.1055 - val_autoencoder_loss: 0.1892\n",
      "Epoch 171/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2499 - energy_loss: 0.0654 - autoencoder_loss: 0.1845 - val_loss: 0.2953 - val_energy_loss: 0.1067 - val_autoencoder_loss: 0.1885\n",
      "Epoch 172/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2497 - energy_loss: 0.0654 - autoencoder_loss: 0.1843 - val_loss: 0.3104 - val_energy_loss: 0.1207 - val_autoencoder_loss: 0.1897\n",
      "Epoch 173/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2496 - energy_loss: 0.0651 - autoencoder_loss: 0.1845 - val_loss: 0.3116 - val_energy_loss: 0.1223 - val_autoencoder_loss: 0.1892\n",
      "Epoch 174/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2494 - energy_loss: 0.0652 - autoencoder_loss: 0.1842 - val_loss: 0.2945 - val_energy_loss: 0.1054 - val_autoencoder_loss: 0.1891\n",
      "Epoch 175/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2492 - energy_loss: 0.0649 - autoencoder_loss: 0.1843 - val_loss: 0.2934 - val_energy_loss: 0.1042 - val_autoencoder_loss: 0.1892\n",
      "Epoch 176/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2499 - energy_loss: 0.0656 - autoencoder_loss: 0.1843 - val_loss: 0.3106 - val_energy_loss: 0.1219 - val_autoencoder_loss: 0.1887\n",
      "Epoch 177/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2496 - energy_loss: 0.0652 - autoencoder_loss: 0.1844 - val_loss: 0.3047 - val_energy_loss: 0.1151 - val_autoencoder_loss: 0.1896\n",
      "Epoch 178/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2496 - energy_loss: 0.0654 - autoencoder_loss: 0.1843 - val_loss: 0.3016 - val_energy_loss: 0.1127 - val_autoencoder_loss: 0.1889\n",
      "Epoch 179/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2484 - energy_loss: 0.0641 - autoencoder_loss: 0.1843 - val_loss: 0.3123 - val_energy_loss: 0.1225 - val_autoencoder_loss: 0.1898\n",
      "Epoch 180/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2491 - energy_loss: 0.0649 - autoencoder_loss: 0.1841 - val_loss: 0.3040 - val_energy_loss: 0.1129 - val_autoencoder_loss: 0.1910\n",
      "Epoch 181/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2492 - energy_loss: 0.0649 - autoencoder_loss: 0.1843 - val_loss: 0.2940 - val_energy_loss: 0.1047 - val_autoencoder_loss: 0.1893\n",
      "Epoch 182/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2483 - energy_loss: 0.0639 - autoencoder_loss: 0.1844 - val_loss: 0.3063 - val_energy_loss: 0.1175 - val_autoencoder_loss: 0.1888\n",
      "Epoch 183/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2488 - energy_loss: 0.0645 - autoencoder_loss: 0.1843 - val_loss: 0.2977 - val_energy_loss: 0.1084 - val_autoencoder_loss: 0.1893\n",
      "Epoch 184/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2483 - energy_loss: 0.0640 - autoencoder_loss: 0.1843 - val_loss: 0.3133 - val_energy_loss: 0.1245 - val_autoencoder_loss: 0.1887\n",
      "Epoch 185/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2487 - energy_loss: 0.0645 - autoencoder_loss: 0.1842 - val_loss: 0.2974 - val_energy_loss: 0.1083 - val_autoencoder_loss: 0.1891\n",
      "Epoch 186/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2474 - energy_loss: 0.0633 - autoencoder_loss: 0.1842 - val_loss: 0.3189 - val_energy_loss: 0.1293 - val_autoencoder_loss: 0.1896\n",
      "Epoch 187/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2480 - energy_loss: 0.0639 - autoencoder_loss: 0.1841 - val_loss: 0.2971 - val_energy_loss: 0.1084 - val_autoencoder_loss: 0.1887\n",
      "Epoch 188/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2480 - energy_loss: 0.0639 - autoencoder_loss: 0.1840 - val_loss: 0.2953 - val_energy_loss: 0.1069 - val_autoencoder_loss: 0.1884\n",
      "Epoch 189/500\n",
      "596/596 [==============================] - 3s 5ms/step - loss: 0.2492 - energy_loss: 0.0649 - autoencoder_loss: 0.1843 - val_loss: 0.3162 - val_energy_loss: 0.1262 - val_autoencoder_loss: 0.1899\n",
      "Epoch 190/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2484 - energy_loss: 0.0642 - autoencoder_loss: 0.1842 - val_loss: 0.2923 - val_energy_loss: 0.1032 - val_autoencoder_loss: 0.1891\n",
      "Epoch 191/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2487 - energy_loss: 0.0646 - autoencoder_loss: 0.1841 - val_loss: 0.2987 - val_energy_loss: 0.1104 - val_autoencoder_loss: 0.1883\n",
      "Epoch 192/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2486 - energy_loss: 0.0642 - autoencoder_loss: 0.1843 - val_loss: 0.3126 - val_energy_loss: 0.1225 - val_autoencoder_loss: 0.1901\n",
      "Epoch 193/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2487 - energy_loss: 0.0644 - autoencoder_loss: 0.1843 - val_loss: 0.2936 - val_energy_loss: 0.1048 - val_autoencoder_loss: 0.1887\n",
      "Epoch 194/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2479 - energy_loss: 0.0636 - autoencoder_loss: 0.1843 - val_loss: 0.2943 - val_energy_loss: 0.1059 - val_autoencoder_loss: 0.1884\n",
      "Epoch 195/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2476 - energy_loss: 0.0637 - autoencoder_loss: 0.1839 - val_loss: 0.3021 - val_energy_loss: 0.1130 - val_autoencoder_loss: 0.1891\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2473 - energy_loss: 0.0630 - autoencoder_loss: 0.1842 - val_loss: 0.3107 - val_energy_loss: 0.1226 - val_autoencoder_loss: 0.1881\n",
      "Epoch 197/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2476 - energy_loss: 0.0634 - autoencoder_loss: 0.1842 - val_loss: 0.2997 - val_energy_loss: 0.1094 - val_autoencoder_loss: 0.1902\n",
      "Epoch 198/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2477 - energy_loss: 0.0636 - autoencoder_loss: 0.1841 - val_loss: 0.3105 - val_energy_loss: 0.1213 - val_autoencoder_loss: 0.1892\n",
      "Epoch 199/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2479 - energy_loss: 0.0638 - autoencoder_loss: 0.1841 - val_loss: 0.2943 - val_energy_loss: 0.1048 - val_autoencoder_loss: 0.1894\n",
      "Epoch 200/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2473 - energy_loss: 0.0631 - autoencoder_loss: 0.1842 - val_loss: 0.2990 - val_energy_loss: 0.1095 - val_autoencoder_loss: 0.1895\n",
      "Epoch 201/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2472 - energy_loss: 0.0632 - autoencoder_loss: 0.1840 - val_loss: 0.2952 - val_energy_loss: 0.1067 - val_autoencoder_loss: 0.1886\n",
      "Epoch 202/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2471 - energy_loss: 0.0631 - autoencoder_loss: 0.1840 - val_loss: 0.3110 - val_energy_loss: 0.1218 - val_autoencoder_loss: 0.1892\n",
      "Epoch 203/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2481 - energy_loss: 0.0641 - autoencoder_loss: 0.1840 - val_loss: 0.2950 - val_energy_loss: 0.1056 - val_autoencoder_loss: 0.1894\n",
      "Epoch 204/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2476 - energy_loss: 0.0635 - autoencoder_loss: 0.1840 - val_loss: 0.3011 - val_energy_loss: 0.1123 - val_autoencoder_loss: 0.1888\n",
      "Epoch 205/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2483 - energy_loss: 0.0641 - autoencoder_loss: 0.1842 - val_loss: 0.3088 - val_energy_loss: 0.1204 - val_autoencoder_loss: 0.1884\n",
      "Epoch 206/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2473 - energy_loss: 0.0635 - autoencoder_loss: 0.1838 - val_loss: 0.3099 - val_energy_loss: 0.1212 - val_autoencoder_loss: 0.1887\n",
      "Epoch 207/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2467 - energy_loss: 0.0627 - autoencoder_loss: 0.1840 - val_loss: 0.3101 - val_energy_loss: 0.1217 - val_autoencoder_loss: 0.1885\n",
      "Epoch 208/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2467 - energy_loss: 0.0627 - autoencoder_loss: 0.1839 - val_loss: 0.3056 - val_energy_loss: 0.1166 - val_autoencoder_loss: 0.1890\n",
      "Epoch 209/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2475 - energy_loss: 0.0636 - autoencoder_loss: 0.1839 - val_loss: 0.3007 - val_energy_loss: 0.1115 - val_autoencoder_loss: 0.1892\n",
      "Epoch 210/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2469 - energy_loss: 0.0629 - autoencoder_loss: 0.1839 - val_loss: 0.3013 - val_energy_loss: 0.1118 - val_autoencoder_loss: 0.1894\n",
      "Epoch 211/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2457 - energy_loss: 0.0616 - autoencoder_loss: 0.1841 - val_loss: 0.2981 - val_energy_loss: 0.1083 - val_autoencoder_loss: 0.1898\n",
      "Epoch 212/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2470 - energy_loss: 0.0630 - autoencoder_loss: 0.1840 - val_loss: 0.3106 - val_energy_loss: 0.1216 - val_autoencoder_loss: 0.1890\n",
      "Epoch 213/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2460 - energy_loss: 0.0622 - autoencoder_loss: 0.1838 - val_loss: 0.2963 - val_energy_loss: 0.1079 - val_autoencoder_loss: 0.1884\n",
      "Epoch 214/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2460 - energy_loss: 0.0620 - autoencoder_loss: 0.1840 - val_loss: 0.3083 - val_energy_loss: 0.1199 - val_autoencoder_loss: 0.1885\n",
      "Epoch 215/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2459 - energy_loss: 0.0620 - autoencoder_loss: 0.1839 - val_loss: 0.2958 - val_energy_loss: 0.1077 - val_autoencoder_loss: 0.1881\n",
      "Epoch 216/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2461 - energy_loss: 0.0622 - autoencoder_loss: 0.1839 - val_loss: 0.3079 - val_energy_loss: 0.1188 - val_autoencoder_loss: 0.1892\n",
      "Epoch 217/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2458 - energy_loss: 0.0619 - autoencoder_loss: 0.1838 - val_loss: 0.2970 - val_energy_loss: 0.1088 - val_autoencoder_loss: 0.1882\n",
      "Epoch 218/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2468 - energy_loss: 0.0630 - autoencoder_loss: 0.1838 - val_loss: 0.2965 - val_energy_loss: 0.1083 - val_autoencoder_loss: 0.1882\n",
      "Epoch 219/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2460 - energy_loss: 0.0621 - autoencoder_loss: 0.1838 - val_loss: 0.3079 - val_energy_loss: 0.1187 - val_autoencoder_loss: 0.1891\n",
      "Epoch 220/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2458 - energy_loss: 0.0620 - autoencoder_loss: 0.1838 - val_loss: 0.3050 - val_energy_loss: 0.1162 - val_autoencoder_loss: 0.1888\n",
      "Epoch 221/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2460 - energy_loss: 0.0620 - autoencoder_loss: 0.1840 - val_loss: 0.3148 - val_energy_loss: 0.1252 - val_autoencoder_loss: 0.1896\n",
      "Epoch 222/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2463 - energy_loss: 0.0624 - autoencoder_loss: 0.1839 - val_loss: 0.2918 - val_energy_loss: 0.1031 - val_autoencoder_loss: 0.1886\n",
      "Epoch 223/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2454 - energy_loss: 0.0616 - autoencoder_loss: 0.1838 - val_loss: 0.3067 - val_energy_loss: 0.1175 - val_autoencoder_loss: 0.1892\n",
      "Epoch 224/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2461 - energy_loss: 0.0621 - autoencoder_loss: 0.1840 - val_loss: 0.3076 - val_energy_loss: 0.1198 - val_autoencoder_loss: 0.1879\n",
      "Epoch 225/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2453 - energy_loss: 0.0616 - autoencoder_loss: 0.1838 - val_loss: 0.3046 - val_energy_loss: 0.1157 - val_autoencoder_loss: 0.1889\n",
      "Epoch 226/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2446 - energy_loss: 0.0610 - autoencoder_loss: 0.1837 - val_loss: 0.3123 - val_energy_loss: 0.1235 - val_autoencoder_loss: 0.1888\n",
      "Epoch 227/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2463 - energy_loss: 0.0624 - autoencoder_loss: 0.1839 - val_loss: 0.3198 - val_energy_loss: 0.1301 - val_autoencoder_loss: 0.1897\n",
      "Epoch 228/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2464 - energy_loss: 0.0627 - autoencoder_loss: 0.1837 - val_loss: 0.2995 - val_energy_loss: 0.1101 - val_autoencoder_loss: 0.1894\n",
      "Epoch 229/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2451 - energy_loss: 0.0613 - autoencoder_loss: 0.1838 - val_loss: 0.2998 - val_energy_loss: 0.1110 - val_autoencoder_loss: 0.1888\n",
      "Epoch 230/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2457 - energy_loss: 0.0621 - autoencoder_loss: 0.1836 - val_loss: 0.3009 - val_energy_loss: 0.1113 - val_autoencoder_loss: 0.1895\n",
      "Epoch 231/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2466 - energy_loss: 0.0627 - autoencoder_loss: 0.1839 - val_loss: 0.3005 - val_energy_loss: 0.1115 - val_autoencoder_loss: 0.1891\n",
      "Epoch 232/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2451 - energy_loss: 0.0615 - autoencoder_loss: 0.1836 - val_loss: 0.3014 - val_energy_loss: 0.1126 - val_autoencoder_loss: 0.1888\n",
      "Epoch 233/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2447 - energy_loss: 0.0611 - autoencoder_loss: 0.1836 - val_loss: 0.3052 - val_energy_loss: 0.1167 - val_autoencoder_loss: 0.1886\n",
      "Epoch 234/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2447 - energy_loss: 0.0612 - autoencoder_loss: 0.1836 - val_loss: 0.3021 - val_energy_loss: 0.1125 - val_autoencoder_loss: 0.1896\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2453 - energy_loss: 0.0616 - autoencoder_loss: 0.1837 - val_loss: 0.2989 - val_energy_loss: 0.1104 - val_autoencoder_loss: 0.1886\n",
      "Epoch 236/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2451 - energy_loss: 0.0614 - autoencoder_loss: 0.1837 - val_loss: 0.3036 - val_energy_loss: 0.1148 - val_autoencoder_loss: 0.1888\n",
      "Epoch 237/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2450 - energy_loss: 0.0613 - autoencoder_loss: 0.1837 - val_loss: 0.2979 - val_energy_loss: 0.1094 - val_autoencoder_loss: 0.1885\n",
      "Epoch 238/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2457 - energy_loss: 0.0619 - autoencoder_loss: 0.1837 - val_loss: 0.2959 - val_energy_loss: 0.1069 - val_autoencoder_loss: 0.1890\n",
      "Epoch 239/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2439 - energy_loss: 0.0604 - autoencoder_loss: 0.1835 - val_loss: 0.2983 - val_energy_loss: 0.1086 - val_autoencoder_loss: 0.1897\n",
      "Epoch 240/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2453 - energy_loss: 0.0617 - autoencoder_loss: 0.1836 - val_loss: 0.3101 - val_energy_loss: 0.1207 - val_autoencoder_loss: 0.1894\n",
      "Epoch 241/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2461 - energy_loss: 0.0623 - autoencoder_loss: 0.1838 - val_loss: 0.2984 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1892\n",
      "Epoch 242/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2441 - energy_loss: 0.0607 - autoencoder_loss: 0.1834 - val_loss: 0.3083 - val_energy_loss: 0.1206 - val_autoencoder_loss: 0.1877\n",
      "Epoch 243/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2448 - energy_loss: 0.0612 - autoencoder_loss: 0.1836 - val_loss: 0.3069 - val_energy_loss: 0.1185 - val_autoencoder_loss: 0.1884\n",
      "Epoch 244/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2446 - energy_loss: 0.0610 - autoencoder_loss: 0.1836 - val_loss: 0.2995 - val_energy_loss: 0.1112 - val_autoencoder_loss: 0.1883\n",
      "Epoch 245/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2447 - energy_loss: 0.0612 - autoencoder_loss: 0.1835 - val_loss: 0.2964 - val_energy_loss: 0.1078 - val_autoencoder_loss: 0.1886\n",
      "Epoch 246/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2453 - energy_loss: 0.0617 - autoencoder_loss: 0.1836 - val_loss: 0.2965 - val_energy_loss: 0.1082 - val_autoencoder_loss: 0.1883\n",
      "Epoch 247/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2450 - energy_loss: 0.0613 - autoencoder_loss: 0.1837 - val_loss: 0.2925 - val_energy_loss: 0.1038 - val_autoencoder_loss: 0.1887\n",
      "Epoch 248/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2444 - energy_loss: 0.0609 - autoencoder_loss: 0.1835 - val_loss: 0.3126 - val_energy_loss: 0.1238 - val_autoencoder_loss: 0.1888\n",
      "Epoch 249/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2443 - energy_loss: 0.0608 - autoencoder_loss: 0.1835 - val_loss: 0.2971 - val_energy_loss: 0.1087 - val_autoencoder_loss: 0.1884\n",
      "Epoch 250/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2447 - energy_loss: 0.0612 - autoencoder_loss: 0.1835 - val_loss: 0.3128 - val_energy_loss: 0.1235 - val_autoencoder_loss: 0.1893\n",
      "Epoch 251/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2454 - energy_loss: 0.0617 - autoencoder_loss: 0.1836 - val_loss: 0.3072 - val_energy_loss: 0.1182 - val_autoencoder_loss: 0.1890\n",
      "Epoch 252/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2454 - energy_loss: 0.0617 - autoencoder_loss: 0.1837 - val_loss: 0.3042 - val_energy_loss: 0.1153 - val_autoencoder_loss: 0.1889\n",
      "Epoch 253/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2441 - energy_loss: 0.0605 - autoencoder_loss: 0.1835 - val_loss: 0.3026 - val_energy_loss: 0.1139 - val_autoencoder_loss: 0.1888\n",
      "Epoch 254/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2445 - energy_loss: 0.0609 - autoencoder_loss: 0.1836 - val_loss: 0.2999 - val_energy_loss: 0.1113 - val_autoencoder_loss: 0.1885\n",
      "Epoch 255/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2439 - energy_loss: 0.0605 - autoencoder_loss: 0.1834 - val_loss: 0.2992 - val_energy_loss: 0.1103 - val_autoencoder_loss: 0.1889\n",
      "Epoch 256/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2445 - energy_loss: 0.0610 - autoencoder_loss: 0.1835 - val_loss: 0.2995 - val_energy_loss: 0.1101 - val_autoencoder_loss: 0.1894\n",
      "Epoch 257/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2454 - energy_loss: 0.0618 - autoencoder_loss: 0.1836 - val_loss: 0.2944 - val_energy_loss: 0.1049 - val_autoencoder_loss: 0.1895\n",
      "Epoch 258/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2445 - energy_loss: 0.0610 - autoencoder_loss: 0.1835 - val_loss: 0.3036 - val_energy_loss: 0.1135 - val_autoencoder_loss: 0.1901\n",
      "Epoch 259/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2441 - energy_loss: 0.0606 - autoencoder_loss: 0.1835 - val_loss: 0.2974 - val_energy_loss: 0.1081 - val_autoencoder_loss: 0.1893\n",
      "Epoch 260/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2442 - energy_loss: 0.0607 - autoencoder_loss: 0.1835 - val_loss: 0.2964 - val_energy_loss: 0.1084 - val_autoencoder_loss: 0.1879\n",
      "Epoch 261/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2442 - energy_loss: 0.0608 - autoencoder_loss: 0.1834 - val_loss: 0.3009 - val_energy_loss: 0.1124 - val_autoencoder_loss: 0.1885\n",
      "Epoch 262/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2436 - energy_loss: 0.0602 - autoencoder_loss: 0.1835 - val_loss: 0.3079 - val_energy_loss: 0.1191 - val_autoencoder_loss: 0.1888\n",
      "Epoch 263/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2434 - energy_loss: 0.0599 - autoencoder_loss: 0.1835 - val_loss: 0.2960 - val_energy_loss: 0.1070 - val_autoencoder_loss: 0.1891\n",
      "Epoch 264/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2439 - energy_loss: 0.0606 - autoencoder_loss: 0.1833 - val_loss: 0.3128 - val_energy_loss: 0.1241 - val_autoencoder_loss: 0.1887\n",
      "Epoch 265/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2432 - energy_loss: 0.0597 - autoencoder_loss: 0.1835 - val_loss: 0.2958 - val_energy_loss: 0.1072 - val_autoencoder_loss: 0.1886\n",
      "Epoch 266/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2438 - energy_loss: 0.0604 - autoencoder_loss: 0.1834 - val_loss: 0.3010 - val_energy_loss: 0.1129 - val_autoencoder_loss: 0.1881\n",
      "Epoch 267/500\n",
      "596/596 [==============================] - 3s 5ms/step - loss: 0.2433 - energy_loss: 0.0599 - autoencoder_loss: 0.1833 - val_loss: 0.2940 - val_energy_loss: 0.1061 - val_autoencoder_loss: 0.1880\n",
      "Epoch 268/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2437 - energy_loss: 0.0604 - autoencoder_loss: 0.1833 - val_loss: 0.3039 - val_energy_loss: 0.1162 - val_autoencoder_loss: 0.1877\n",
      "Epoch 269/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2438 - energy_loss: 0.0604 - autoencoder_loss: 0.1834 - val_loss: 0.2955 - val_energy_loss: 0.1066 - val_autoencoder_loss: 0.1889\n",
      "Epoch 270/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2436 - energy_loss: 0.0602 - autoencoder_loss: 0.1833 - val_loss: 0.3017 - val_energy_loss: 0.1127 - val_autoencoder_loss: 0.1890\n",
      "Epoch 271/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2437 - energy_loss: 0.0604 - autoencoder_loss: 0.1834 - val_loss: 0.2974 - val_energy_loss: 0.1088 - val_autoencoder_loss: 0.1887\n",
      "Epoch 272/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2445 - energy_loss: 0.0612 - autoencoder_loss: 0.1834 - val_loss: 0.3011 - val_energy_loss: 0.1128 - val_autoencoder_loss: 0.1883\n",
      "Epoch 273/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2425 - energy_loss: 0.0592 - autoencoder_loss: 0.1833 - val_loss: 0.2953 - val_energy_loss: 0.1071 - val_autoencoder_loss: 0.1881\n",
      "Epoch 274/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2427 - energy_loss: 0.0596 - autoencoder_loss: 0.1831 - val_loss: 0.3021 - val_energy_loss: 0.1131 - val_autoencoder_loss: 0.1890\n",
      "Epoch 275/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2431 - energy_loss: 0.0599 - autoencoder_loss: 0.1832 - val_loss: 0.3087 - val_energy_loss: 0.1201 - val_autoencoder_loss: 0.1886\n",
      "Epoch 276/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2443 - energy_loss: 0.0610 - autoencoder_loss: 0.1833 - val_loss: 0.3063 - val_energy_loss: 0.1171 - val_autoencoder_loss: 0.1893\n",
      "Epoch 277/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2434 - energy_loss: 0.0601 - autoencoder_loss: 0.1833 - val_loss: 0.2897 - val_energy_loss: 0.1013 - val_autoencoder_loss: 0.1883\n",
      "Epoch 278/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2432 - energy_loss: 0.0600 - autoencoder_loss: 0.1832 - val_loss: 0.2975 - val_energy_loss: 0.1089 - val_autoencoder_loss: 0.1886\n",
      "Epoch 279/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2424 - energy_loss: 0.0592 - autoencoder_loss: 0.1832 - val_loss: 0.2946 - val_energy_loss: 0.1052 - val_autoencoder_loss: 0.1894\n",
      "Epoch 280/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2428 - energy_loss: 0.0595 - autoencoder_loss: 0.1833 - val_loss: 0.2955 - val_energy_loss: 0.1068 - val_autoencoder_loss: 0.1887\n",
      "Epoch 281/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2430 - energy_loss: 0.0596 - autoencoder_loss: 0.1833 - val_loss: 0.2999 - val_energy_loss: 0.1107 - val_autoencoder_loss: 0.1892\n",
      "Epoch 282/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2433 - energy_loss: 0.0600 - autoencoder_loss: 0.1833 - val_loss: 0.2959 - val_energy_loss: 0.1071 - val_autoencoder_loss: 0.1888\n",
      "Epoch 283/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2430 - energy_loss: 0.0598 - autoencoder_loss: 0.1832 - val_loss: 0.3034 - val_energy_loss: 0.1144 - val_autoencoder_loss: 0.1890\n",
      "Epoch 284/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2422 - energy_loss: 0.0589 - autoencoder_loss: 0.1834 - val_loss: 0.3078 - val_energy_loss: 0.1197 - val_autoencoder_loss: 0.1881\n",
      "Epoch 285/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2427 - energy_loss: 0.0594 - autoencoder_loss: 0.1832 - val_loss: 0.2927 - val_energy_loss: 0.1049 - val_autoencoder_loss: 0.1878\n",
      "Epoch 286/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2436 - energy_loss: 0.0604 - autoencoder_loss: 0.1832 - val_loss: 0.3014 - val_energy_loss: 0.1130 - val_autoencoder_loss: 0.1884\n",
      "Epoch 287/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2435 - energy_loss: 0.0603 - autoencoder_loss: 0.1832 - val_loss: 0.2967 - val_energy_loss: 0.1071 - val_autoencoder_loss: 0.1896\n",
      "Epoch 288/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2428 - energy_loss: 0.0597 - autoencoder_loss: 0.1832 - val_loss: 0.2992 - val_energy_loss: 0.1106 - val_autoencoder_loss: 0.1886\n",
      "Epoch 289/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2430 - energy_loss: 0.0598 - autoencoder_loss: 0.1833 - val_loss: 0.3037 - val_energy_loss: 0.1146 - val_autoencoder_loss: 0.1892\n",
      "Epoch 290/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2419 - energy_loss: 0.0587 - autoencoder_loss: 0.1832 - val_loss: 0.3094 - val_energy_loss: 0.1215 - val_autoencoder_loss: 0.1879\n",
      "Epoch 291/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2416 - energy_loss: 0.0585 - autoencoder_loss: 0.1831 - val_loss: 0.3070 - val_energy_loss: 0.1190 - val_autoencoder_loss: 0.1880\n",
      "Epoch 292/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2428 - energy_loss: 0.0595 - autoencoder_loss: 0.1833 - val_loss: 0.2962 - val_energy_loss: 0.1075 - val_autoencoder_loss: 0.1887\n",
      "Epoch 293/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2431 - energy_loss: 0.0598 - autoencoder_loss: 0.1833 - val_loss: 0.2977 - val_energy_loss: 0.1080 - val_autoencoder_loss: 0.1897\n",
      "Epoch 294/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2424 - energy_loss: 0.0590 - autoencoder_loss: 0.1834 - val_loss: 0.3015 - val_energy_loss: 0.1123 - val_autoencoder_loss: 0.1892\n",
      "Epoch 295/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2426 - energy_loss: 0.0593 - autoencoder_loss: 0.1833 - val_loss: 0.2905 - val_energy_loss: 0.1013 - val_autoencoder_loss: 0.1892\n",
      "Epoch 296/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2434 - energy_loss: 0.0601 - autoencoder_loss: 0.1833 - val_loss: 0.2984 - val_energy_loss: 0.1102 - val_autoencoder_loss: 0.1882\n",
      "Epoch 297/500\n",
      "596/596 [==============================] - 3s 5ms/step - loss: 0.2421 - energy_loss: 0.0589 - autoencoder_loss: 0.1832 - val_loss: 0.2947 - val_energy_loss: 0.1054 - val_autoencoder_loss: 0.1893\n",
      "Epoch 298/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2420 - energy_loss: 0.0589 - autoencoder_loss: 0.1831 - val_loss: 0.3013 - val_energy_loss: 0.1124 - val_autoencoder_loss: 0.1889\n",
      "Epoch 299/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2426 - energy_loss: 0.0594 - autoencoder_loss: 0.1833 - val_loss: 0.3052 - val_energy_loss: 0.1163 - val_autoencoder_loss: 0.1889\n",
      "Epoch 300/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2425 - energy_loss: 0.0592 - autoencoder_loss: 0.1833 - val_loss: 0.2944 - val_energy_loss: 0.1060 - val_autoencoder_loss: 0.1884\n",
      "Epoch 301/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2424 - energy_loss: 0.0591 - autoencoder_loss: 0.1833 - val_loss: 0.2994 - val_energy_loss: 0.1104 - val_autoencoder_loss: 0.1890\n",
      "Epoch 302/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2429 - energy_loss: 0.0595 - autoencoder_loss: 0.1834 - val_loss: 0.3001 - val_energy_loss: 0.1120 - val_autoencoder_loss: 0.1881\n",
      "Epoch 303/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2421 - energy_loss: 0.0590 - autoencoder_loss: 0.1831 - val_loss: 0.2970 - val_energy_loss: 0.1086 - val_autoencoder_loss: 0.1884\n",
      "Epoch 304/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2416 - energy_loss: 0.0585 - autoencoder_loss: 0.1831 - val_loss: 0.2998 - val_energy_loss: 0.1116 - val_autoencoder_loss: 0.1882\n",
      "Epoch 305/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2421 - energy_loss: 0.0589 - autoencoder_loss: 0.1831 - val_loss: 0.3051 - val_energy_loss: 0.1164 - val_autoencoder_loss: 0.1888\n",
      "Epoch 306/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2427 - energy_loss: 0.0594 - autoencoder_loss: 0.1833 - val_loss: 0.2939 - val_energy_loss: 0.1058 - val_autoencoder_loss: 0.1881\n",
      "Epoch 307/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2421 - energy_loss: 0.0589 - autoencoder_loss: 0.1832 - val_loss: 0.3037 - val_energy_loss: 0.1151 - val_autoencoder_loss: 0.1886\n",
      "Epoch 308/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2420 - energy_loss: 0.0588 - autoencoder_loss: 0.1832 - val_loss: 0.2924 - val_energy_loss: 0.1039 - val_autoencoder_loss: 0.1885\n",
      "Epoch 309/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2416 - energy_loss: 0.0585 - autoencoder_loss: 0.1831 - val_loss: 0.3034 - val_energy_loss: 0.1148 - val_autoencoder_loss: 0.1886\n",
      "Epoch 310/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2421 - energy_loss: 0.0588 - autoencoder_loss: 0.1832 - val_loss: 0.2994 - val_energy_loss: 0.1111 - val_autoencoder_loss: 0.1884\n",
      "Epoch 311/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2423 - energy_loss: 0.0588 - autoencoder_loss: 0.1834 - val_loss: 0.2924 - val_energy_loss: 0.1036 - val_autoencoder_loss: 0.1888\n",
      "Epoch 312/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2415 - energy_loss: 0.0584 - autoencoder_loss: 0.1831 - val_loss: 0.2962 - val_energy_loss: 0.1071 - val_autoencoder_loss: 0.1891\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2415 - energy_loss: 0.0583 - autoencoder_loss: 0.1831 - val_loss: 0.2984 - val_energy_loss: 0.1091 - val_autoencoder_loss: 0.1893\n",
      "Epoch 314/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2411 - energy_loss: 0.0580 - autoencoder_loss: 0.1830 - val_loss: 0.3037 - val_energy_loss: 0.1156 - val_autoencoder_loss: 0.1880\n",
      "Epoch 315/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2422 - energy_loss: 0.0592 - autoencoder_loss: 0.1831 - val_loss: 0.3012 - val_energy_loss: 0.1130 - val_autoencoder_loss: 0.1882\n",
      "Epoch 316/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2421 - energy_loss: 0.0589 - autoencoder_loss: 0.1832 - val_loss: 0.2942 - val_energy_loss: 0.1065 - val_autoencoder_loss: 0.1877\n",
      "Epoch 317/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2418 - energy_loss: 0.0585 - autoencoder_loss: 0.1833 - val_loss: 0.2983 - val_energy_loss: 0.1094 - val_autoencoder_loss: 0.1889\n",
      "Epoch 318/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2416 - energy_loss: 0.0584 - autoencoder_loss: 0.1832 - val_loss: 0.3079 - val_energy_loss: 0.1174 - val_autoencoder_loss: 0.1905\n",
      "Epoch 319/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2415 - energy_loss: 0.0584 - autoencoder_loss: 0.1831 - val_loss: 0.3194 - val_energy_loss: 0.1289 - val_autoencoder_loss: 0.1905\n",
      "Epoch 320/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2407 - energy_loss: 0.0577 - autoencoder_loss: 0.1830 - val_loss: 0.3013 - val_energy_loss: 0.1124 - val_autoencoder_loss: 0.1889\n",
      "Epoch 321/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2412 - energy_loss: 0.0581 - autoencoder_loss: 0.1832 - val_loss: 0.3032 - val_energy_loss: 0.1150 - val_autoencoder_loss: 0.1882\n",
      "Epoch 322/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2414 - energy_loss: 0.0583 - autoencoder_loss: 0.1831 - val_loss: 0.3038 - val_energy_loss: 0.1156 - val_autoencoder_loss: 0.1883\n",
      "Epoch 323/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2414 - energy_loss: 0.0584 - autoencoder_loss: 0.1829 - val_loss: 0.3065 - val_energy_loss: 0.1180 - val_autoencoder_loss: 0.1885\n",
      "Epoch 324/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2409 - energy_loss: 0.0579 - autoencoder_loss: 0.1830 - val_loss: 0.3096 - val_energy_loss: 0.1213 - val_autoencoder_loss: 0.1883\n",
      "Epoch 325/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2412 - energy_loss: 0.0581 - autoencoder_loss: 0.1830 - val_loss: 0.2908 - val_energy_loss: 0.1027 - val_autoencoder_loss: 0.1881\n",
      "Epoch 326/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2415 - energy_loss: 0.0583 - autoencoder_loss: 0.1832 - val_loss: 0.3033 - val_energy_loss: 0.1141 - val_autoencoder_loss: 0.1893\n",
      "Epoch 327/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2413 - energy_loss: 0.0583 - autoencoder_loss: 0.1830 - val_loss: 0.2985 - val_energy_loss: 0.1093 - val_autoencoder_loss: 0.1892\n",
      "Epoch 328/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2413 - energy_loss: 0.0581 - autoencoder_loss: 0.1832 - val_loss: 0.3033 - val_energy_loss: 0.1146 - val_autoencoder_loss: 0.1887\n",
      "Epoch 329/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2412 - energy_loss: 0.0581 - autoencoder_loss: 0.1831 - val_loss: 0.2925 - val_energy_loss: 0.1041 - val_autoencoder_loss: 0.1884\n",
      "Epoch 330/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2414 - energy_loss: 0.0583 - autoencoder_loss: 0.1831 - val_loss: 0.3035 - val_energy_loss: 0.1144 - val_autoencoder_loss: 0.1891\n",
      "Epoch 331/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2419 - energy_loss: 0.0588 - autoencoder_loss: 0.1831 - val_loss: 0.3116 - val_energy_loss: 0.1236 - val_autoencoder_loss: 0.1880\n",
      "Epoch 332/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2408 - energy_loss: 0.0577 - autoencoder_loss: 0.1830 - val_loss: 0.2974 - val_energy_loss: 0.1085 - val_autoencoder_loss: 0.1889\n",
      "Epoch 333/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2403 - energy_loss: 0.0573 - autoencoder_loss: 0.1830 - val_loss: 0.2952 - val_energy_loss: 0.1073 - val_autoencoder_loss: 0.1879\n",
      "Epoch 334/500\n",
      "596/596 [==============================] - 3s 5ms/step - loss: 0.2412 - energy_loss: 0.0582 - autoencoder_loss: 0.1830 - val_loss: 0.2980 - val_energy_loss: 0.1106 - val_autoencoder_loss: 0.1873\n",
      "Epoch 335/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2408 - energy_loss: 0.0578 - autoencoder_loss: 0.1829 - val_loss: 0.3058 - val_energy_loss: 0.1172 - val_autoencoder_loss: 0.1886\n",
      "Epoch 336/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2411 - energy_loss: 0.0580 - autoencoder_loss: 0.1831 - val_loss: 0.3069 - val_energy_loss: 0.1180 - val_autoencoder_loss: 0.1889\n",
      "Epoch 337/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2418 - energy_loss: 0.0587 - autoencoder_loss: 0.1832 - val_loss: 0.2913 - val_energy_loss: 0.1034 - val_autoencoder_loss: 0.1880\n",
      "Epoch 338/500\n",
      "596/596 [==============================] - 3s 4ms/step - loss: 0.2405 - energy_loss: 0.0576 - autoencoder_loss: 0.1830 - val_loss: 0.3057 - val_energy_loss: 0.1161 - val_autoencoder_loss: 0.1896\n",
      "Epoch 339/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2411 - energy_loss: 0.0580 - autoencoder_loss: 0.1831 - val_loss: 0.3010 - val_energy_loss: 0.1131 - val_autoencoder_loss: 0.1879\n",
      "Epoch 340/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2410 - energy_loss: 0.0579 - autoencoder_loss: 0.1831 - val_loss: 0.2950 - val_energy_loss: 0.1066 - val_autoencoder_loss: 0.1885\n",
      "Epoch 341/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2401 - energy_loss: 0.0570 - autoencoder_loss: 0.1831 - val_loss: 0.2961 - val_energy_loss: 0.1067 - val_autoencoder_loss: 0.1894\n",
      "Epoch 342/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2405 - energy_loss: 0.0574 - autoencoder_loss: 0.1831 - val_loss: 0.2965 - val_energy_loss: 0.1087 - val_autoencoder_loss: 0.1878\n",
      "Epoch 343/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2409 - energy_loss: 0.0579 - autoencoder_loss: 0.1830 - val_loss: 0.3026 - val_energy_loss: 0.1139 - val_autoencoder_loss: 0.1887\n",
      "Epoch 344/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2406 - energy_loss: 0.0575 - autoencoder_loss: 0.1830 - val_loss: 0.3010 - val_energy_loss: 0.1125 - val_autoencoder_loss: 0.1885\n",
      "Epoch 345/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2415 - energy_loss: 0.0584 - autoencoder_loss: 0.1831 - val_loss: 0.2952 - val_energy_loss: 0.1069 - val_autoencoder_loss: 0.1883\n",
      "Epoch 346/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2400 - energy_loss: 0.0569 - autoencoder_loss: 0.1830 - val_loss: 0.3056 - val_energy_loss: 0.1177 - val_autoencoder_loss: 0.1879\n",
      "Epoch 347/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0571 - autoencoder_loss: 0.1831 - val_loss: 0.2887 - val_energy_loss: 0.1008 - val_autoencoder_loss: 0.1879\n",
      "Epoch 348/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2401 - energy_loss: 0.0572 - autoencoder_loss: 0.1828 - val_loss: 0.2892 - val_energy_loss: 0.1013 - val_autoencoder_loss: 0.1879\n",
      "Epoch 349/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2401 - energy_loss: 0.0570 - autoencoder_loss: 0.1831 - val_loss: 0.2970 - val_energy_loss: 0.1083 - val_autoencoder_loss: 0.1887\n",
      "Epoch 350/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2407 - energy_loss: 0.0576 - autoencoder_loss: 0.1831 - val_loss: 0.2962 - val_energy_loss: 0.1082 - val_autoencoder_loss: 0.1881\n",
      "Epoch 351/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2398 - energy_loss: 0.0567 - autoencoder_loss: 0.1831 - val_loss: 0.3049 - val_energy_loss: 0.1164 - val_autoencoder_loss: 0.1884\n",
      "Epoch 352/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2408 - energy_loss: 0.0578 - autoencoder_loss: 0.1830 - val_loss: 0.2930 - val_energy_loss: 0.1049 - val_autoencoder_loss: 0.1882\n",
      "Epoch 353/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2409 - energy_loss: 0.0578 - autoencoder_loss: 0.1831 - val_loss: 0.2929 - val_energy_loss: 0.1043 - val_autoencoder_loss: 0.1886\n",
      "Epoch 354/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2404 - energy_loss: 0.0574 - autoencoder_loss: 0.1831 - val_loss: 0.2983 - val_energy_loss: 0.1094 - val_autoencoder_loss: 0.1890\n",
      "Epoch 355/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0571 - autoencoder_loss: 0.1831 - val_loss: 0.2986 - val_energy_loss: 0.1100 - val_autoencoder_loss: 0.1886\n",
      "Epoch 356/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2398 - energy_loss: 0.0569 - autoencoder_loss: 0.1829 - val_loss: 0.2977 - val_energy_loss: 0.1095 - val_autoencoder_loss: 0.1882\n",
      "Epoch 357/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0566 - autoencoder_loss: 0.1830 - val_loss: 0.2962 - val_energy_loss: 0.1082 - val_autoencoder_loss: 0.1880\n",
      "Epoch 358/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2412 - energy_loss: 0.0580 - autoencoder_loss: 0.1832 - val_loss: 0.2976 - val_energy_loss: 0.1095 - val_autoencoder_loss: 0.1880\n",
      "Epoch 359/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0571 - autoencoder_loss: 0.1831 - val_loss: 0.3040 - val_energy_loss: 0.1164 - val_autoencoder_loss: 0.1877\n",
      "Epoch 360/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2406 - energy_loss: 0.0574 - autoencoder_loss: 0.1832 - val_loss: 0.3084 - val_energy_loss: 0.1179 - val_autoencoder_loss: 0.1905\n",
      "Epoch 361/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2400 - energy_loss: 0.0570 - autoencoder_loss: 0.1830 - val_loss: 0.2975 - val_energy_loss: 0.1094 - val_autoencoder_loss: 0.1881\n",
      "Epoch 362/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0566 - autoencoder_loss: 0.1831 - val_loss: 0.2940 - val_energy_loss: 0.1067 - val_autoencoder_loss: 0.1872\n",
      "Epoch 363/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2399 - energy_loss: 0.0570 - autoencoder_loss: 0.1830 - val_loss: 0.2991 - val_energy_loss: 0.1097 - val_autoencoder_loss: 0.1895\n",
      "Epoch 364/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2411 - energy_loss: 0.0578 - autoencoder_loss: 0.1833 - val_loss: 0.2979 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1888\n",
      "Epoch 365/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2404 - energy_loss: 0.0573 - autoencoder_loss: 0.1830 - val_loss: 0.2992 - val_energy_loss: 0.1107 - val_autoencoder_loss: 0.1884\n",
      "Epoch 366/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2415 - energy_loss: 0.0583 - autoencoder_loss: 0.1831 - val_loss: 0.2997 - val_energy_loss: 0.1113 - val_autoencoder_loss: 0.1883\n",
      "Epoch 367/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2390 - energy_loss: 0.0560 - autoencoder_loss: 0.1830 - val_loss: 0.2918 - val_energy_loss: 0.1037 - val_autoencoder_loss: 0.1881\n",
      "Epoch 368/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2400 - energy_loss: 0.0569 - autoencoder_loss: 0.1831 - val_loss: 0.2992 - val_energy_loss: 0.1110 - val_autoencoder_loss: 0.1882\n",
      "Epoch 369/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2398 - energy_loss: 0.0566 - autoencoder_loss: 0.1832 - val_loss: 0.2894 - val_energy_loss: 0.1005 - val_autoencoder_loss: 0.1889\n",
      "Epoch 370/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0570 - autoencoder_loss: 0.1831 - val_loss: 0.2967 - val_energy_loss: 0.1082 - val_autoencoder_loss: 0.1885\n",
      "Epoch 371/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2401 - energy_loss: 0.0569 - autoencoder_loss: 0.1832 - val_loss: 0.3046 - val_energy_loss: 0.1157 - val_autoencoder_loss: 0.1889\n",
      "Epoch 372/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0568 - autoencoder_loss: 0.1828 - val_loss: 0.3025 - val_energy_loss: 0.1129 - val_autoencoder_loss: 0.1896\n",
      "Epoch 373/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0572 - autoencoder_loss: 0.1831 - val_loss: 0.3006 - val_energy_loss: 0.1115 - val_autoencoder_loss: 0.1891\n",
      "Epoch 374/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2403 - energy_loss: 0.0572 - autoencoder_loss: 0.1830 - val_loss: 0.3088 - val_energy_loss: 0.1200 - val_autoencoder_loss: 0.1888\n",
      "Epoch 375/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0565 - autoencoder_loss: 0.1831 - val_loss: 0.3045 - val_energy_loss: 0.1161 - val_autoencoder_loss: 0.1883\n",
      "Epoch 376/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2388 - energy_loss: 0.0560 - autoencoder_loss: 0.1828 - val_loss: 0.3058 - val_energy_loss: 0.1181 - val_autoencoder_loss: 0.1877\n",
      "Epoch 377/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2400 - energy_loss: 0.0569 - autoencoder_loss: 0.1830 - val_loss: 0.2976 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1884\n",
      "Epoch 378/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2400 - energy_loss: 0.0570 - autoencoder_loss: 0.1830 - val_loss: 0.3019 - val_energy_loss: 0.1136 - val_autoencoder_loss: 0.1884\n",
      "Epoch 379/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2395 - energy_loss: 0.0566 - autoencoder_loss: 0.1829 - val_loss: 0.2970 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1878\n",
      "Epoch 380/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2397 - energy_loss: 0.0566 - autoencoder_loss: 0.1831 - val_loss: 0.3040 - val_energy_loss: 0.1158 - val_autoencoder_loss: 0.1882\n",
      "Epoch 381/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2393 - energy_loss: 0.0563 - autoencoder_loss: 0.1830 - val_loss: 0.2928 - val_energy_loss: 0.1048 - val_autoencoder_loss: 0.1879\n",
      "Epoch 382/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2389 - energy_loss: 0.0559 - autoencoder_loss: 0.1830 - val_loss: 0.2945 - val_energy_loss: 0.1054 - val_autoencoder_loss: 0.1891\n",
      "Epoch 383/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2395 - energy_loss: 0.0567 - autoencoder_loss: 0.1828 - val_loss: 0.3034 - val_energy_loss: 0.1154 - val_autoencoder_loss: 0.1880\n",
      "Epoch 384/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0564 - autoencoder_loss: 0.1832 - val_loss: 0.3083 - val_energy_loss: 0.1201 - val_autoencoder_loss: 0.1881\n",
      "Epoch 385/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2393 - energy_loss: 0.0564 - autoencoder_loss: 0.1829 - val_loss: 0.3033 - val_energy_loss: 0.1145 - val_autoencoder_loss: 0.1888\n",
      "Epoch 386/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0572 - autoencoder_loss: 0.1830 - val_loss: 0.3073 - val_energy_loss: 0.1192 - val_autoencoder_loss: 0.1882\n",
      "Epoch 387/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2390 - energy_loss: 0.0561 - autoencoder_loss: 0.1829 - val_loss: 0.2979 - val_energy_loss: 0.1095 - val_autoencoder_loss: 0.1884\n",
      "Epoch 388/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0573 - autoencoder_loss: 0.1828 - val_loss: 0.3076 - val_energy_loss: 0.1197 - val_autoencoder_loss: 0.1879\n",
      "Epoch 389/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2392 - energy_loss: 0.0563 - autoencoder_loss: 0.1829 - val_loss: 0.2959 - val_energy_loss: 0.1074 - val_autoencoder_loss: 0.1885\n",
      "Epoch 390/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2394 - energy_loss: 0.0565 - autoencoder_loss: 0.1829 - val_loss: 0.2945 - val_energy_loss: 0.1059 - val_autoencoder_loss: 0.1886\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2392 - energy_loss: 0.0562 - autoencoder_loss: 0.1830 - val_loss: 0.2951 - val_energy_loss: 0.1061 - val_autoencoder_loss: 0.1889\n",
      "Epoch 392/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2398 - energy_loss: 0.0567 - autoencoder_loss: 0.1831 - val_loss: 0.2939 - val_energy_loss: 0.1060 - val_autoencoder_loss: 0.1880\n",
      "Epoch 393/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2400 - energy_loss: 0.0569 - autoencoder_loss: 0.1831 - val_loss: 0.2957 - val_energy_loss: 0.1078 - val_autoencoder_loss: 0.1879\n",
      "Epoch 394/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2387 - energy_loss: 0.0558 - autoencoder_loss: 0.1828 - val_loss: 0.3000 - val_energy_loss: 0.1118 - val_autoencoder_loss: 0.1882\n",
      "Epoch 395/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0566 - autoencoder_loss: 0.1830 - val_loss: 0.2982 - val_energy_loss: 0.1095 - val_autoencoder_loss: 0.1887\n",
      "Epoch 396/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2391 - energy_loss: 0.0563 - autoencoder_loss: 0.1828 - val_loss: 0.2936 - val_energy_loss: 0.1054 - val_autoencoder_loss: 0.1882\n",
      "Epoch 397/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2389 - energy_loss: 0.0561 - autoencoder_loss: 0.1828 - val_loss: 0.3002 - val_energy_loss: 0.1104 - val_autoencoder_loss: 0.1898\n",
      "Epoch 398/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2402 - energy_loss: 0.0571 - autoencoder_loss: 0.1831 - val_loss: 0.3014 - val_energy_loss: 0.1134 - val_autoencoder_loss: 0.1880\n",
      "Epoch 399/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0566 - autoencoder_loss: 0.1830 - val_loss: 0.2963 - val_energy_loss: 0.1084 - val_autoencoder_loss: 0.1879\n",
      "Epoch 400/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2387 - energy_loss: 0.0559 - autoencoder_loss: 0.1828 - val_loss: 0.2946 - val_energy_loss: 0.1059 - val_autoencoder_loss: 0.1887\n",
      "Epoch 401/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2394 - energy_loss: 0.0564 - autoencoder_loss: 0.1829 - val_loss: 0.2990 - val_energy_loss: 0.1099 - val_autoencoder_loss: 0.1891\n",
      "Epoch 402/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2396 - energy_loss: 0.0566 - autoencoder_loss: 0.1830 - val_loss: 0.3075 - val_energy_loss: 0.1190 - val_autoencoder_loss: 0.1885\n",
      "Epoch 403/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2392 - energy_loss: 0.0563 - autoencoder_loss: 0.1829 - val_loss: 0.2971 - val_energy_loss: 0.1081 - val_autoencoder_loss: 0.1891\n",
      "Epoch 404/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2387 - energy_loss: 0.0558 - autoencoder_loss: 0.1829 - val_loss: 0.2940 - val_energy_loss: 0.1057 - val_autoencoder_loss: 0.1882\n",
      "Epoch 405/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2394 - energy_loss: 0.0563 - autoencoder_loss: 0.1830 - val_loss: 0.3059 - val_energy_loss: 0.1168 - val_autoencoder_loss: 0.1891\n",
      "Epoch 406/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2390 - energy_loss: 0.0560 - autoencoder_loss: 0.1831 - val_loss: 0.2957 - val_energy_loss: 0.1070 - val_autoencoder_loss: 0.1887\n",
      "Epoch 407/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2385 - energy_loss: 0.0554 - autoencoder_loss: 0.1830 - val_loss: 0.3012 - val_energy_loss: 0.1124 - val_autoencoder_loss: 0.1888\n",
      "Epoch 408/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2392 - energy_loss: 0.0563 - autoencoder_loss: 0.1830 - val_loss: 0.2972 - val_energy_loss: 0.1085 - val_autoencoder_loss: 0.1886\n",
      "Epoch 409/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2387 - energy_loss: 0.0559 - autoencoder_loss: 0.1828 - val_loss: 0.3011 - val_energy_loss: 0.1128 - val_autoencoder_loss: 0.1882\n",
      "Epoch 410/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2390 - energy_loss: 0.0562 - autoencoder_loss: 0.1829 - val_loss: 0.2971 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1879\n",
      "Epoch 411/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2399 - energy_loss: 0.0567 - autoencoder_loss: 0.1832 - val_loss: 0.3023 - val_energy_loss: 0.1145 - val_autoencoder_loss: 0.1878\n",
      "Epoch 412/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2388 - energy_loss: 0.0558 - autoencoder_loss: 0.1830 - val_loss: 0.3096 - val_energy_loss: 0.1207 - val_autoencoder_loss: 0.1889\n",
      "Epoch 413/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2392 - energy_loss: 0.0565 - autoencoder_loss: 0.1828 - val_loss: 0.3137 - val_energy_loss: 0.1259 - val_autoencoder_loss: 0.1878\n",
      "Epoch 414/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0550 - autoencoder_loss: 0.1829 - val_loss: 0.2974 - val_energy_loss: 0.1084 - val_autoencoder_loss: 0.1890\n",
      "Epoch 415/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2386 - energy_loss: 0.0558 - autoencoder_loss: 0.1828 - val_loss: 0.2927 - val_energy_loss: 0.1038 - val_autoencoder_loss: 0.1889\n",
      "Epoch 416/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2395 - energy_loss: 0.0565 - autoencoder_loss: 0.1831 - val_loss: 0.2954 - val_energy_loss: 0.1055 - val_autoencoder_loss: 0.1900\n",
      "Epoch 417/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2395 - energy_loss: 0.0565 - autoencoder_loss: 0.1830 - val_loss: 0.2997 - val_energy_loss: 0.1112 - val_autoencoder_loss: 0.1884\n",
      "Epoch 418/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2390 - energy_loss: 0.0561 - autoencoder_loss: 0.1830 - val_loss: 0.3067 - val_energy_loss: 0.1175 - val_autoencoder_loss: 0.1891\n",
      "Epoch 419/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2383 - energy_loss: 0.0554 - autoencoder_loss: 0.1829 - val_loss: 0.3072 - val_energy_loss: 0.1178 - val_autoencoder_loss: 0.1894\n",
      "Epoch 420/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2397 - energy_loss: 0.0567 - autoencoder_loss: 0.1830 - val_loss: 0.2999 - val_energy_loss: 0.1111 - val_autoencoder_loss: 0.1888\n",
      "Epoch 421/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2385 - energy_loss: 0.0558 - autoencoder_loss: 0.1827 - val_loss: 0.3091 - val_energy_loss: 0.1211 - val_autoencoder_loss: 0.1880\n",
      "Epoch 422/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2385 - energy_loss: 0.0557 - autoencoder_loss: 0.1828 - val_loss: 0.2952 - val_energy_loss: 0.1071 - val_autoencoder_loss: 0.1881\n",
      "Epoch 423/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2382 - energy_loss: 0.0552 - autoencoder_loss: 0.1829 - val_loss: 0.2997 - val_energy_loss: 0.1111 - val_autoencoder_loss: 0.1886\n",
      "Epoch 424/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2378 - energy_loss: 0.0550 - autoencoder_loss: 0.1829 - val_loss: 0.3017 - val_energy_loss: 0.1133 - val_autoencoder_loss: 0.1884\n",
      "Epoch 425/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2385 - energy_loss: 0.0555 - autoencoder_loss: 0.1829 - val_loss: 0.3053 - val_energy_loss: 0.1171 - val_autoencoder_loss: 0.1881\n",
      "Epoch 426/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2384 - energy_loss: 0.0556 - autoencoder_loss: 0.1828 - val_loss: 0.2962 - val_energy_loss: 0.1072 - val_autoencoder_loss: 0.1890\n",
      "Epoch 427/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2386 - energy_loss: 0.0556 - autoencoder_loss: 0.1830 - val_loss: 0.2934 - val_energy_loss: 0.1046 - val_autoencoder_loss: 0.1889\n",
      "Epoch 428/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2384 - energy_loss: 0.0557 - autoencoder_loss: 0.1827 - val_loss: 0.2986 - val_energy_loss: 0.1099 - val_autoencoder_loss: 0.1887\n",
      "Epoch 429/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2383 - energy_loss: 0.0552 - autoencoder_loss: 0.1832 - val_loss: 0.3037 - val_energy_loss: 0.1152 - val_autoencoder_loss: 0.1885\n",
      "Epoch 430/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2380 - energy_loss: 0.0552 - autoencoder_loss: 0.1829 - val_loss: 0.3069 - val_energy_loss: 0.1190 - val_autoencoder_loss: 0.1879\n",
      "Epoch 431/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2392 - energy_loss: 0.0561 - autoencoder_loss: 0.1830 - val_loss: 0.3047 - val_energy_loss: 0.1162 - val_autoencoder_loss: 0.1886\n",
      "Epoch 432/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2386 - energy_loss: 0.0557 - autoencoder_loss: 0.1828 - val_loss: 0.2956 - val_energy_loss: 0.1073 - val_autoencoder_loss: 0.1883\n",
      "Epoch 433/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2381 - energy_loss: 0.0552 - autoencoder_loss: 0.1828 - val_loss: 0.3018 - val_energy_loss: 0.1135 - val_autoencoder_loss: 0.1883\n",
      "Epoch 434/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2387 - energy_loss: 0.0556 - autoencoder_loss: 0.1831 - val_loss: 0.3008 - val_energy_loss: 0.1129 - val_autoencoder_loss: 0.1879\n",
      "Epoch 435/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2382 - energy_loss: 0.0553 - autoencoder_loss: 0.1828 - val_loss: 0.2991 - val_energy_loss: 0.1103 - val_autoencoder_loss: 0.1888\n",
      "Epoch 436/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2387 - energy_loss: 0.0558 - autoencoder_loss: 0.1829 - val_loss: 0.2961 - val_energy_loss: 0.1088 - val_autoencoder_loss: 0.1873\n",
      "Epoch 437/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2387 - energy_loss: 0.0558 - autoencoder_loss: 0.1829 - val_loss: 0.3052 - val_energy_loss: 0.1172 - val_autoencoder_loss: 0.1879\n",
      "Epoch 438/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2385 - energy_loss: 0.0557 - autoencoder_loss: 0.1828 - val_loss: 0.2961 - val_energy_loss: 0.1083 - val_autoencoder_loss: 0.1878\n",
      "Epoch 439/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2380 - energy_loss: 0.0550 - autoencoder_loss: 0.1829 - val_loss: 0.2986 - val_energy_loss: 0.1102 - val_autoencoder_loss: 0.1883\n",
      "Epoch 440/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2378 - energy_loss: 0.0549 - autoencoder_loss: 0.1829 - val_loss: 0.3041 - val_energy_loss: 0.1158 - val_autoencoder_loss: 0.1883\n",
      "Epoch 441/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2390 - energy_loss: 0.0561 - autoencoder_loss: 0.1829 - val_loss: 0.3079 - val_energy_loss: 0.1195 - val_autoencoder_loss: 0.1884\n",
      "Epoch 442/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2380 - energy_loss: 0.0551 - autoencoder_loss: 0.1829 - val_loss: 0.3017 - val_energy_loss: 0.1127 - val_autoencoder_loss: 0.1890\n",
      "Epoch 443/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2390 - energy_loss: 0.0561 - autoencoder_loss: 0.1829 - val_loss: 0.2923 - val_energy_loss: 0.1036 - val_autoencoder_loss: 0.1887\n",
      "Epoch 444/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2374 - energy_loss: 0.0546 - autoencoder_loss: 0.1828 - val_loss: 0.3021 - val_energy_loss: 0.1135 - val_autoencoder_loss: 0.1885\n",
      "Epoch 445/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2383 - energy_loss: 0.0553 - autoencoder_loss: 0.1830 - val_loss: 0.3075 - val_energy_loss: 0.1184 - val_autoencoder_loss: 0.1891\n",
      "Epoch 446/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2382 - energy_loss: 0.0552 - autoencoder_loss: 0.1830 - val_loss: 0.2946 - val_energy_loss: 0.1058 - val_autoencoder_loss: 0.1888\n",
      "Epoch 447/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2376 - energy_loss: 0.0548 - autoencoder_loss: 0.1828 - val_loss: 0.3016 - val_energy_loss: 0.1132 - val_autoencoder_loss: 0.1884\n",
      "Epoch 448/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2374 - energy_loss: 0.0547 - autoencoder_loss: 0.1827 - val_loss: 0.3022 - val_energy_loss: 0.1147 - val_autoencoder_loss: 0.1876\n",
      "Epoch 449/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2389 - energy_loss: 0.0560 - autoencoder_loss: 0.1829 - val_loss: 0.3067 - val_energy_loss: 0.1177 - val_autoencoder_loss: 0.1889\n",
      "Epoch 450/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2374 - energy_loss: 0.0545 - autoencoder_loss: 0.1829 - val_loss: 0.3038 - val_energy_loss: 0.1155 - val_autoencoder_loss: 0.1883\n",
      "Epoch 451/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0551 - autoencoder_loss: 0.1829 - val_loss: 0.2938 - val_energy_loss: 0.1050 - val_autoencoder_loss: 0.1889\n",
      "Epoch 452/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2384 - energy_loss: 0.0554 - autoencoder_loss: 0.1830 - val_loss: 0.2986 - val_energy_loss: 0.1102 - val_autoencoder_loss: 0.1884\n",
      "Epoch 453/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2381 - energy_loss: 0.0554 - autoencoder_loss: 0.1827 - val_loss: 0.3014 - val_energy_loss: 0.1132 - val_autoencoder_loss: 0.1882\n",
      "Epoch 454/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2386 - energy_loss: 0.0558 - autoencoder_loss: 0.1827 - val_loss: 0.2980 - val_energy_loss: 0.1094 - val_autoencoder_loss: 0.1886\n",
      "Epoch 455/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0551 - autoencoder_loss: 0.1828 - val_loss: 0.3092 - val_energy_loss: 0.1209 - val_autoencoder_loss: 0.1883\n",
      "Epoch 456/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2380 - energy_loss: 0.0552 - autoencoder_loss: 0.1828 - val_loss: 0.3016 - val_energy_loss: 0.1138 - val_autoencoder_loss: 0.1877\n",
      "Epoch 457/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0550 - autoencoder_loss: 0.1829 - val_loss: 0.3032 - val_energy_loss: 0.1154 - val_autoencoder_loss: 0.1878\n",
      "Epoch 458/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0551 - autoencoder_loss: 0.1828 - val_loss: 0.3004 - val_energy_loss: 0.1112 - val_autoencoder_loss: 0.1892\n",
      "Epoch 459/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2384 - energy_loss: 0.0553 - autoencoder_loss: 0.1831 - val_loss: 0.2992 - val_energy_loss: 0.1106 - val_autoencoder_loss: 0.1886\n",
      "Epoch 460/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2380 - energy_loss: 0.0551 - autoencoder_loss: 0.1828 - val_loss: 0.3039 - val_energy_loss: 0.1159 - val_autoencoder_loss: 0.1880\n",
      "Epoch 461/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2380 - energy_loss: 0.0551 - autoencoder_loss: 0.1829 - val_loss: 0.2969 - val_energy_loss: 0.1092 - val_autoencoder_loss: 0.1877\n",
      "Epoch 462/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2373 - energy_loss: 0.0546 - autoencoder_loss: 0.1827 - val_loss: 0.2989 - val_energy_loss: 0.1102 - val_autoencoder_loss: 0.1887\n",
      "Epoch 463/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2386 - energy_loss: 0.0558 - autoencoder_loss: 0.1828 - val_loss: 0.3027 - val_energy_loss: 0.1142 - val_autoencoder_loss: 0.1885\n",
      "Epoch 464/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2373 - energy_loss: 0.0546 - autoencoder_loss: 0.1827 - val_loss: 0.3039 - val_energy_loss: 0.1150 - val_autoencoder_loss: 0.1889\n",
      "Epoch 465/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2376 - energy_loss: 0.0545 - autoencoder_loss: 0.1830 - val_loss: 0.2992 - val_energy_loss: 0.1109 - val_autoencoder_loss: 0.1883\n",
      "Epoch 466/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2377 - energy_loss: 0.0547 - autoencoder_loss: 0.1829 - val_loss: 0.3004 - val_energy_loss: 0.1122 - val_autoencoder_loss: 0.1882\n",
      "Epoch 467/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0551 - autoencoder_loss: 0.1829 - val_loss: 0.2899 - val_energy_loss: 0.1018 - val_autoencoder_loss: 0.1881\n",
      "Epoch 468/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2374 - energy_loss: 0.0549 - autoencoder_loss: 0.1825 - val_loss: 0.2918 - val_energy_loss: 0.1029 - val_autoencoder_loss: 0.1889\n",
      "Epoch 469/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2374 - energy_loss: 0.0547 - autoencoder_loss: 0.1828 - val_loss: 0.2983 - val_energy_loss: 0.1103 - val_autoencoder_loss: 0.1880\n",
      "Epoch 470/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0549 - autoencoder_loss: 0.1830 - val_loss: 0.2941 - val_energy_loss: 0.1066 - val_autoencoder_loss: 0.1875\n",
      "Epoch 471/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2372 - energy_loss: 0.0545 - autoencoder_loss: 0.1827 - val_loss: 0.3001 - val_energy_loss: 0.1124 - val_autoencoder_loss: 0.1877\n",
      "Epoch 472/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2374 - energy_loss: 0.0544 - autoencoder_loss: 0.1830 - val_loss: 0.2979 - val_energy_loss: 0.1095 - val_autoencoder_loss: 0.1884\n",
      "Epoch 473/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2370 - energy_loss: 0.0542 - autoencoder_loss: 0.1828 - val_loss: 0.2935 - val_energy_loss: 0.1053 - val_autoencoder_loss: 0.1882\n",
      "Epoch 474/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2378 - energy_loss: 0.0550 - autoencoder_loss: 0.1827 - val_loss: 0.3064 - val_energy_loss: 0.1179 - val_autoencoder_loss: 0.1884\n",
      "Epoch 475/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0550 - autoencoder_loss: 0.1829 - val_loss: 0.3004 - val_energy_loss: 0.1128 - val_autoencoder_loss: 0.1877\n",
      "Epoch 476/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2383 - energy_loss: 0.0555 - autoencoder_loss: 0.1828 - val_loss: 0.2945 - val_energy_loss: 0.1052 - val_autoencoder_loss: 0.1893\n",
      "Epoch 477/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2386 - energy_loss: 0.0556 - autoencoder_loss: 0.1830 - val_loss: 0.2981 - val_energy_loss: 0.1097 - val_autoencoder_loss: 0.1885\n",
      "Epoch 478/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2368 - energy_loss: 0.0539 - autoencoder_loss: 0.1828 - val_loss: 0.2975 - val_energy_loss: 0.1096 - val_autoencoder_loss: 0.1879\n",
      "Epoch 479/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2370 - energy_loss: 0.0543 - autoencoder_loss: 0.1828 - val_loss: 0.2991 - val_energy_loss: 0.1105 - val_autoencoder_loss: 0.1886\n",
      "Epoch 480/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2371 - energy_loss: 0.0543 - autoencoder_loss: 0.1828 - val_loss: 0.3127 - val_energy_loss: 0.1249 - val_autoencoder_loss: 0.1878\n",
      "Epoch 481/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2378 - energy_loss: 0.0548 - autoencoder_loss: 0.1830 - val_loss: 0.3081 - val_energy_loss: 0.1198 - val_autoencoder_loss: 0.1883\n",
      "Epoch 482/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2382 - energy_loss: 0.0551 - autoencoder_loss: 0.1830 - val_loss: 0.2973 - val_energy_loss: 0.1079 - val_autoencoder_loss: 0.1894\n",
      "Epoch 483/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2379 - energy_loss: 0.0549 - autoencoder_loss: 0.1829 - val_loss: 0.3012 - val_energy_loss: 0.1131 - val_autoencoder_loss: 0.1882\n",
      "Epoch 484/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2386 - energy_loss: 0.0558 - autoencoder_loss: 0.1828 - val_loss: 0.3045 - val_energy_loss: 0.1166 - val_autoencoder_loss: 0.1878\n",
      "Epoch 485/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2366 - energy_loss: 0.0537 - autoencoder_loss: 0.1829 - val_loss: 0.3039 - val_energy_loss: 0.1141 - val_autoencoder_loss: 0.1898\n",
      "Epoch 486/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2376 - energy_loss: 0.0546 - autoencoder_loss: 0.1830 - val_loss: 0.2975 - val_energy_loss: 0.1090 - val_autoencoder_loss: 0.1885\n",
      "Epoch 487/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2361 - energy_loss: 0.0534 - autoencoder_loss: 0.1827 - val_loss: 0.3023 - val_energy_loss: 0.1133 - val_autoencoder_loss: 0.1890\n",
      "Epoch 488/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2374 - energy_loss: 0.0546 - autoencoder_loss: 0.1828 - val_loss: 0.3026 - val_energy_loss: 0.1139 - val_autoencoder_loss: 0.1886\n",
      "Epoch 489/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2373 - energy_loss: 0.0544 - autoencoder_loss: 0.1829 - val_loss: 0.2960 - val_energy_loss: 0.1070 - val_autoencoder_loss: 0.1890\n",
      "Epoch 490/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2373 - energy_loss: 0.0545 - autoencoder_loss: 0.1829 - val_loss: 0.2947 - val_energy_loss: 0.1057 - val_autoencoder_loss: 0.1890\n",
      "Epoch 491/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2365 - energy_loss: 0.0536 - autoencoder_loss: 0.1829 - val_loss: 0.3040 - val_energy_loss: 0.1157 - val_autoencoder_loss: 0.1883\n",
      "Epoch 492/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2377 - energy_loss: 0.0548 - autoencoder_loss: 0.1829 - val_loss: 0.2908 - val_energy_loss: 0.1024 - val_autoencoder_loss: 0.1884\n",
      "Epoch 493/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2367 - energy_loss: 0.0539 - autoencoder_loss: 0.1827 - val_loss: 0.2940 - val_energy_loss: 0.1062 - val_autoencoder_loss: 0.1878\n",
      "Epoch 494/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2361 - energy_loss: 0.0532 - autoencoder_loss: 0.1829 - val_loss: 0.2956 - val_energy_loss: 0.1068 - val_autoencoder_loss: 0.1888\n",
      "Epoch 495/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2378 - energy_loss: 0.0546 - autoencoder_loss: 0.1832 - val_loss: 0.2942 - val_energy_loss: 0.1058 - val_autoencoder_loss: 0.1884\n",
      "Epoch 496/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2375 - energy_loss: 0.0544 - autoencoder_loss: 0.1830 - val_loss: 0.2933 - val_energy_loss: 0.1054 - val_autoencoder_loss: 0.1879\n",
      "Epoch 497/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2367 - energy_loss: 0.0540 - autoencoder_loss: 0.1827 - val_loss: 0.2924 - val_energy_loss: 0.1029 - val_autoencoder_loss: 0.1894\n",
      "Epoch 498/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2373 - energy_loss: 0.0546 - autoencoder_loss: 0.1827 - val_loss: 0.2961 - val_energy_loss: 0.1082 - val_autoencoder_loss: 0.1879\n",
      "Epoch 499/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2369 - energy_loss: 0.0542 - autoencoder_loss: 0.1827 - val_loss: 0.2993 - val_energy_loss: 0.1117 - val_autoencoder_loss: 0.1877\n",
      "Epoch 500/500\n",
      "596/596 [==============================] - 2s 4ms/step - loss: 0.2370 - energy_loss: 0.0542 - autoencoder_loss: 0.1828 - val_loss: 0.3095 - val_energy_loss: 0.1212 - val_autoencoder_loss: 0.1884\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_features,\n",
    "                 {'energy': y_train, 'autoencoder': x_train_features},\n",
    "                 epochs=500,\n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 validation_data=(x_test_features, {'energy': y_test, 'autoencoder': x_test_features}),\n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.framework.test_util.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
